{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c707a4f-d592-4803-93b3-0bfedfab8d95",
   "metadata": {},
   "source": [
    "# LLM Architecture from Scratch (GPT-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00142cac-7109-44a6-85d5-e4890f7768ad",
   "metadata": {},
   "source": [
    "## 1. Overview of Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "751183b8-0825-4f08-b6c5-51316270a32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f33b9-09d4-4422-be73-7011b762b811",
   "metadata": {},
   "source": [
    "### Demo: Dummy GPT Model Class\n",
    "\n",
    "<b>Step 1</b>: Use a placeholder for TransformerBlock\n",
    "\n",
    "<b>Step 2</b>: Use a placeholder for LayerNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1db8435-4419-482c-a18b-5bccda8454be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DummyGPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        # Use a placeholder for TransformerBlock\n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[DummyTransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        # Use a placeholder for LayerNorm\n",
    "        self.final_norm = DummyLayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits\n",
    "\n",
    "\n",
    "class DummyTransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # A simple placeholder\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This block does nothing and just returns its input.\n",
    "        return x\n",
    "\n",
    "\n",
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        # The parameters here are just to mimic the LayerNorm interface.\n",
    "\n",
    "    def forward(self, x):\n",
    "        # This layer does nothing and just returns its input.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d6af25-350e-43a4-8b6b-62837106bfa1",
   "metadata": {},
   "source": [
    "The DummyGPTModel class in this code defines a simplified version of a GPT-like model using PyTorch's neural network module (nn.Module). The model architecture in the DummyGPTModel class consists of token and positional embeddings, dropout, a series of transformer blocks (DummyTransformerBlock), a final layer normalization (DummyLayerNorm), and a linear output layer (out_head). The configuration is passed in via a Python dictionary, for instance, the GPT_CONFIG_124M dictionary we created earlier.\n",
    "\n",
    "The forward method describes the data flow through the model, it computes token and positional embeddings for the input indices, applies dropout, processes the data through the transformer blocks, applies normalization, and finally produces logits with the linear output layer.\n",
    "\n",
    "The code above is already functional, as we will see later in this section after we prepare the input data. However, for now, note in the code above that we have used placeholders (DummyLayerNorm and DummyTransformerBlock) for the transformer block and layer normalization, which we will develop in later sections.\n",
    "\n",
    "Next, we will prepare the input data and initialize a new GPT model to illustrate its usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff33567-379b-45e5-a5f9-eab0ba40b4ec",
   "metadata": {},
   "source": [
    "### Step 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df4c641a-41f2-4956-8f2b-03e66c0fc6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c35ca3-f97e-41bb-bc5b-e36f9c04e18d",
   "metadata": {},
   "source": [
    "### Step 1: Create an instance of Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fac3cf6-8dfe-4693-87ae-2e693fd6c55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[-1.2034,  0.3201, -0.7130,  ..., -1.5548, -0.2390, -0.4667],\n",
      "         [-0.1192,  0.4539, -0.4432,  ...,  0.2392,  1.3469,  1.2430],\n",
      "         [ 0.5307,  1.6720, -0.4695,  ...,  1.1966,  0.0111,  0.5835],\n",
      "         [ 0.0139,  1.6755, -0.3388,  ...,  1.1586, -0.0435, -1.0400]],\n",
      "\n",
      "        [[-1.0908,  0.1798, -0.9484,  ..., -1.6047,  0.2439, -0.4530],\n",
      "         [-0.7860,  0.5581, -0.0610,  ...,  0.4835, -0.0077,  1.6621],\n",
      "         [ 0.3567,  1.2698, -0.6398,  ..., -0.0162, -0.1296,  0.3717],\n",
      "         [-0.2407, -0.7349, -0.5102,  ...,  2.0057, -0.3694,  0.1814]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = DummyGPTModel(GPT_CONFIG_124M)\n",
    "logits = model(batch)\n",
    "print(\"Output shape:\", logits.shape)\n",
    "print(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d79fbe6-8bd5-41c8-9cad-dcbc0182f548",
   "metadata": {},
   "source": [
    "The output tensor has two rows corresponding to the two text samples. Each text sample consists of 4 tokens; each token is a 50,257-dimensional vector, which matches the size of the tokenizer's vocabulary.\n",
    "\n",
    "The embedding has 50,257 dimensions because each of these dimensions refers to a unique token in the vocabulary. At the end of this chapter, when we implement the postprocessing code, we will convert these 50,257-dimensional vectors back into token IDs, which we can then decode into words.\n",
    "\n",
    "Now that we have taken a top-down look at the GPT architecture and its in- and outputs, we will code the individual placeholders in the upcoming sections, starting with the real layer normalization class that will replace the DummyLayerNorm in the previous code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c04ea0a-fd72-4685-a23c-47e4a3f6bdaa",
   "metadata": {},
   "source": [
    "## 2. Implementing Layer Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fdcc34-ba06-42f6-9932-c1d3fb34cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2260, 0.3470, 0.0000, 0.2216, 0.0000, 0.0000],\n",
      "        [0.2133, 0.2394, 0.0000, 0.5198, 0.3297, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "batch_example = torch.randn(2, 5) #A\n",
    "layer = nn.Sequential(nn.Linear(5, 6), nn.ReLU())\n",
    "out = layer(batch_example)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ddb01c-f6a9-4f48-a8f2-92142051c12a",
   "metadata": {},
   "source": [
    "The neural network layer we have coded consists of a Linear layer followed by a non-linear activation function, ReLU (short for Rectified Linear Unit), which is a standard activation function in neural networks.\n",
    "\n",
    "If you are unfamiliar with ReLU, it simply thresholds negative inputs to 0, ensuring that a layer outputs only positive values, which explains why the resulting layer output does not contain any negative values. Note that we will use another, more sophisticated activation function in GPT, which we will introduce in the next section.\n",
    "\n",
    "Before we apply layer normalization to these outputs, let's examine the mean and variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3aee80cc-f130-43de-a568-00031387ffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.1324],\n",
      "        [0.2170]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[0.0231],\n",
      "        [0.0398]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mean = out.mean(dim=-1, keepdim=True)\n",
    "var = out.var(dim=-1, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0756975-9fc1-4726-aa50-a18ad18ea1a5",
   "metadata": {},
   "source": [
    "The first row in the mean tensor above contains the mean value for the first input row, and the second output row contains the mean for the second input row.\n",
    "\n",
    "Using keepdim=True in operations like mean or variance calculation ensures that the output tensor retains the same number of dimensions as the input tensor, even though the operation reduces the tensor along the dimension specified via dim. For instance, without keepdim=True, the returned mean tensor would be a 2-dimensional vector [0.1324, 0.2170] instead of a 2Ã—1-dimensional matrix [[0.1324], [0.2170]].\n",
    "\n",
    "For a 2D tensor (like a matrix), using dim=-1 for operations such as mean or variance calculation is the same as using dim=1. This is because -1 refers to the tensor's last dimension, which corresponds to the columns in a 2D tensor. Later, when adding layer normalization to the GPT model, which produces 3D tensors with shape [batch_size, num_tokens, embedding_size], we can still use dim=-1 for normalization across the last dimension, avoiding a change from dim=1 to dim=2.\n",
    "\n",
    "Next, let us apply layer normalization to the layer outputs we obtained earlier. The operation consists of subtracting the mean and dividing by the square root of the variance (also known as standard deviation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e12d18a9-ead3-4c49-85f0-4eed15267bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized layer outputs:\n",
      " tensor([[ 0.6159,  1.4126, -0.8719,  0.5872, -0.8719, -0.8719],\n",
      "        [-0.0189,  0.1121, -1.0876,  1.5173,  0.5647, -1.0876]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "Mean:\n",
      " tensor([[9.9341e-09],\n",
      "        [0.0000e+00]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out_norm = (out - mean) / torch.sqrt(var)\n",
    "mean = out_norm.mean(dim=-1, keepdim=True)\n",
    "var = out_norm.var(dim=-1, keepdim=True)\n",
    "print(\"Normalized layer outputs:\\n\", out_norm)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f3d8db-a954-4d92-b6f6-33de16fe032d",
   "metadata": {},
   "source": [
    "To improve readability, we can also turn off the scientific notation when printing tensor values by setting sci_mode to False:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d4d8a8-e1b8-4b8c-8e62-e09d0bd377a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[0.0000],\n",
      "        [0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61586afc-6a20-4bc6-ad4f-a58e55883f47",
   "metadata": {},
   "source": [
    "Let's now encapsulate this process in a PyTorch module that we can use in the GPT model later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f71d674-4ba1-4167-b11a-13f9e08e2f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641f07ff-75f3-43cd-85eb-40be0da24935",
   "metadata": {},
   "source": [
    "This specific implementation of layer Normalization operates on the last dimension of the input tensor x, which represents the embedding dimension (emb_dim). The variable eps is a small constant (epsilon) added to the variance to prevent division by zero during normalization. The scale and shift are two trainable parameters (of the same dimension as the input) that the LLM automatically adjusts during training if it is determined that doing so would improve the model's performance on its training task. \n",
    "\n",
    "This allows the model to learn appropriate scaling and shifting that best suit the data it is processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c353f77-14a7-4832-bfb3-f2f2fecb4306",
   "metadata": {},
   "source": [
    "<b><u>A small note on biased variance</u></b>:\n",
    "\n",
    "In our variance calculation method, we have opted for an implementation detail by setting unbiased=False.\n",
    "\n",
    "For those curious about what this means, in the variance calculation, we divide by the number of inputs n in the variance formula. This approach does not apply Bessel's correction, which typically uses n-1 instead of n in the denominator to adjust for bias in sample variance estimation. This decision results in a so-called biased estimate of the variance.\n",
    "\n",
    "For large-scale language models (LLMs), where the embedding dimension n is significantly large, the difference between using n and n-1 is practically negligible. We chose this approach to ensure compatibility with the GPT-2 model's normalization layers and because it reflects TensorFlow's default behavior, which was used to implement the original GPT2 model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a6abe3-9ebb-4764-8090-ba45713d11b5",
   "metadata": {},
   "source": [
    "Let's now try the LayerNorm module in practice and apply it to the batch input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb12a103-e77c-4e61-9180-8061d2ef1795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1115,  0.1204, -0.3696, -0.2404, -1.1969],\n",
      "        [ 0.2093, -0.9724, -0.7550,  0.3239, -0.1085]])\n"
     ]
    }
   ],
   "source": [
    "print(batch_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8bb2b89-ad2c-47f0-a19b-77f297dc1ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:\n",
      " tensor([[-0.0000],\n",
      "        [ 0.0000]], grad_fn=<MeanBackward1>)\n",
      "Variance:\n",
      " tensor([[1.0000],\n",
      "        [1.0000]], grad_fn=<VarBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ln = LayerNorm(emb_dim=5)\n",
    "out_ln = ln(batch_example)\n",
    "\n",
    "mean = out_ln.mean(dim=-1, keepdim=True)\n",
    "var = out_ln.var(dim=-1, unbiased=False, keepdim=True)\n",
    "print(\"Mean:\\n\", mean)\n",
    "print(\"Variance:\\n\", var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7825f259-bd23-4744-b6e3-b7cade797343",
   "metadata": {},
   "source": [
    "As we can see based on the results, the layer normalization code works as expected and normalizes the values of each of the two inputs such that they have a mean of 0 and a variance of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808197e4-abb6-4ad8-8472-0d92dd09a564",
   "metadata": {},
   "source": [
    "## 3. Implementing Feed-Forward Neural Network with GELU Activation\n",
    "\n",
    "Let's implement the GELU activation function approximation used by GPT-2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9534947-e56c-4051-94a2-0037ea3eab33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad80191d-b016-423c-8384-bd350f0a074e",
   "metadata": {},
   "source": [
    "To get an idea of what this GELU function looks like and how it compares to the ReLU function, let's plot these functions side by side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73d63f11-9447-45ac-9024-1f954846aefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXexJREFUeJzt3Qd0FNUaB/B/eoMEQkmAhA6hlySCgFKUjoWnIg+lqICKoCCIAiKKqKiIgIAUG4ogRSkKiCCKgIBAQi+RHgIhCS0J6WXf+W7YvJQNsGk7O/v/nTMnu5PZ3bkzydy9c+/3XTuDwWAAERERERFREdgX5cVERERERERsWBARERERUbFgjwURERERERUZGxZERERERFRkbFgQEREREVGRsWFBRERERERFxoYFEREREREVGRsWRERERERUZGxYEBERERFRkbFhQWTCO++8Azs7O4scm0WLFqnPPnfuXKl/dnp6Ol5//XX4+/vD3t4evXv3hhZZ8hgRkW175plnULNmTZurm27evIkhQ4bA19dX7cOoUaOgRZY8RsSGhU06e/YsRowYgfr168Pd3V0tjRo1wvDhw3Ho0CGT/6AFLZcvX1bbyRc8ef7JJ58U+LlyIX7ooYdM/m7fvn3q9fKFsbQkJiaq8m3duhWW8MEHH2DNmjXQkq+//hrTpk3DE088gW+//RavvvqqRfdHi8eISM+MjXbj4ujoiGrVqqkv0xcvXizUe8o1Vt7rxx9/LHAb+b3US6bI6+T3pXmtvnTpkqofDhw4gNJm6brpdtdj+fsYNmwYFi9ejAEDBlhsX7R6jAhw5EGwLevWrUPfvn1VZfH000+jefPm6s70iRMnsGrVKsybN081PGrUqJHrdbK+TJky+d6vXLlysFZyYZo8ebJ63LFjx1y/mzhxIsaNG1fiF2n5Ap+3V0Au1v/973/h4uKC0vbHH3+oLxEzZsyAFmjxGBHZgnfffRe1atVCcnIydu/erb5Q7tixA0eOHIGrqyv0ThoWUj/IDbEWLVrk+t0XX3yBzMxM3dZNt6sf7r33Xrz99tuwNK0eI2LDwqacPn1afRmTRsOWLVtQpUqVXL//6KOP8Pnnn6uGRl7y5a5ixYqwFdLwksUSHBwc1GIJ0dHRVtFYtOQxIrIFPXr0QHBwsHosw1/k+i91xM8//4wnn3wStszJyckm6yapH2R0g9ZZ8hgRh0LZlI8//hgJCQn45ptv8jUqhPwjvvLKK2p8vVZdu3YNr732Gpo2bap6UDw9PVUFePDgwXzbyp026SqVIV9yh03K/Nhjj6kGlgzdqlSpktpO7noYu/1le1NjNJs0aYJOnTrl+wy5ayV3+KXhZSTDwdq2bYsKFSrAzc0NQUFB+YYAyHvLuZDhRsbPlqEGt4sfkEZf48aN1V36qlWrqqFrN27cyLWN3LmRfT127JjaXxnmJvsn5/52jEPZ/vzzTxw9ejR7n6Sb2TiMIW+Xs/E1OYevSRnkvMiQCellkMdynOWcZWRk5Dt2s2bNUudSzo9s1717dzUsTovHiMiW3X///eqnXD9zkt5uuf55e3ur/2NpjEjjwxLOnz+Pl156CQEBAeraK9fgPn36mIzFkuuCDPWUHgm5Xvj5+WHgwIG4cuWKutbdc889artnn302+/pjvNbljLFIS0tTZZft8oqLi1PHRK5/IjU1FZMmTVJ1gpeXFzw8PNRxleuukbl1kzE2bsqUKahTp44qi+zbhAkTkJKSYnI4svQ8tWrVSu1b7dq18d133932uBrrABnNsH79+ux9kn0t6Fpsqt4w59pbnPV3aRwj+j8Gb9vYMKi6deuidevWhfpCLxfcnEveL2yl4cyZM2rMvfzjf/rppxg7diwOHz6MDh06qK5rI/kSK9vIRUcu4tOnT8fIkSMRGxuruvLloiTDu8R//vMfNV5UFrlwmSLDx7Zt25YdU2IkFx/5XOkJMpIvyy1btlRDCWQojzTYpHKTC7KRfJZc3KRSMX72Cy+8UGC55UIpX5Lly7KU5fHHH8eCBQvQtWtXVbHldP36dfUFXYa5ybYNGjTAG2+8gV9//bXA95fjIfsg20oFa9ynhg0bwlxy7Lt166YqdWlkybmR/Vi4cGGu7QYPHqyC/6QhK3dCpetaLuIy7EKLx4jIlhm/OJYvXz57ndyEkKExx48fV/+/8r8kX5blpsLq1atLfR/37t2LnTt3quvxZ599hhdffFH1zssXWhk6kzMIWa4rs2fPVtcHuWbLttJIioiIUNc9uX6L559/Pvv60759e5O9F1KHSL0kDYecZJ18cTXWD9LQ+PLLL9X+yDVPrlkxMTHqemmM5TC3bjL2KEmDJTAwUA1jlWvu1KlTc9VLRqdOnVINwS5duqjzJedTGkpyLgsix0P2QXqtZFiYcZ+MX+7NcTfX3uKuv0vjGFEOBrIJsbGxBjndvXv3zve769evG2JiYrKXxMTE7N+9/fbb6nWmloCAgOztzp49q9ZNmzatwH2oUaOGoVevXiZ/t3fvXvX6b7755rblSE5ONmRkZORaJ5/t4uJiePfdd7PXff311+r9Pv3003zvkZmZqX5KWWUbKWNexnIbhYWFqeezZ8/Otd1LL71kKFOmTK5jlvOxSE1NNTRp0sTwwAMP5Frv4eFhGDRoUL7PlmMgnyXlEtHR0QZnZ2dD165dc5V9zpw5ajspq1GHDh3Uuu+++y57XUpKisHX19fw+OOPG+5EXt+4ceNc6/7880/1nvIzJ+M5z3nOpDyyLue5EC1btjQEBQVlP//jjz/Udq+88kqB50erx4hIz4z/W7///ru6Rl64cMHw448/GipVqqSus/Lc6MEHHzQ0bdpUXZdz/v+2bdvWUK9evXzXkJUrVxb4ufL74cOHm/ydvM7UNSivvNdesWvXrnz/75MmTVLrVq1aVeD153Z1klyTpD4z+u2339S2v/zyS67tevbsaahdu3b28/T0dHWtyVv/+vj4GJ577rnsdebUTQcOHFDPhwwZkmu71157Ta2Xa62R7LOs27ZtW/Y6uXbKeR0zZozhTkzV4XmvxberN+722lvc9XdpHiMyGNhjYSPkTokwFYAtd0/kDoBxmTt3br5tfvrpJ2zevDnXIkOqSpvcwTbGgMhdjatXr6oySdd3aGhorv2Vuysvv/xyvvcoTBo66Y6VOzXLly/PXiefL0OcHn74YdXtbpTzsdydkbsscncs5/6Z4/fff1d3wuTufs74l6FDh6qhYDl7QoQcj/79+2c/d3Z2Vl260ttTWuTuX05S/pyfL+dHzoOpIMDCnB9rPEZEWta5c2dVH0iPoty9lZ4IGeIkPZrGXmwJ5pV4i/j4+OyebLkmyx34kydPFjqLVGHlvPZKL6Xsi/TSS9xY3vpB7pjL3e7iuP488MADqr7JWT/ItV/qSentNpK4MLnWGIeCyjGUIToyfKyw9cOGDRvUz9GjR+daP2bMGPUz77VPYiSMw9qEnGOpP0vr2nc3197irr+t7RhZO0a32IiyZctmdwHnJcNFpGKIiorK9Q+fk3QBl0bw9p0uGsZx+TKWXsZ75hy3L0NvjGQcplwIijOASyoIGZMplaWMC5WxoxLMlrPiMA45e++991TXds7xm4XNqy3jhoWUJye5IMvYT+PvjaTiz/tZ0pWbN5VwSTHGS+T9fKloc54fGbIkY5OLg7UdIyKtkxtMckNFboxIGmoZCpozC5sMF5GOhrfeekstpsj1Ua6VxeVO19CkpCQ1vEVuesl1OqsjJIuUI+f1R4ZKFhepZ+T9li5dqq75cpwky6I0bvLWDxIzJsNrZNhVziGakoGrMOTaJjdTpAGVk8w1IQ2qvNe+6tWr53uPvNfnknQ3197irr+t7RhZOzYsbIQEiknwk4xPzMsYc1HSk43JF0658JtiHP96pzSGErMgldhzzz2nArHki6lcMOROdUmm/xNSQYwfPx4rV65Un7dixQp1XGW8qNH27dvxyCOPqIaYNH7kmMsYXKnopNIpDQVlS8pZyRZHZZ43GPtOn68lxX2MiPRG7iIbs0JJzMR9992Hp556CmFhYequs/F6K4HJ0kNhSt4vcrcjX8aLWj/IHW651sr1uU2bNur6LNcvGUdf0vWDfIbcpJNYATleUj9I/ID0jBh9//33aqy+/F7iAytXrqyuRdIYyhsUb667vXGl1fqhNK69ljpGtoYNCxvSq1cvFTi2Z88eVWmUNklzK9kgTJHKyrjN7cjQI8km8dVXX+VaL4HkOXtUJPPDP//8o+4IFZQa0NweBLmjJMdNurtlIie5IyUVRM67eNKFK5Xfb7/9lmu9qWFjd/v5xmMix0juvhvJ0B/ptZEhCyXJGKyZN1g/710ec8j5kWMkQwFu12thLceISM+MX37l2jtnzhwVqG38P5Pra3H8f8n/sLEeKEr9MGjQINUjkDO7UN5rl1x/TN1kK0r9IDeT5EaS1A/SCJNhYm+++Wa+/ZPjJnVHzvfPOyTUnM+WYyKNJhl6ljPZhoxAkHLf6ZhptX4ozvrb0sfI1jDGwoa8/vrrKr2b3O2Xf6jSbo337NlTZdzIO5OydB1Lg0fu3kjGhjtVcHn3U3oQ8o7llW5pGe8rlWBextfLsRDmZLeSXgvJWiRDA+T983Zzy/7JBS/n3RrpCTI1e7SMWb6bz5ZKW4b0SJaTnGWXxpV070uDsSTJRVfKJUMhcpIemcKS8yNlMU5wlFPOMlrLMSLSO4nFkxsrM2fOVF/W5Xot6+QufWRkZL7tJduRufWDXFtDQkJyrZf//yVLlqgYNxm6Ym79IJmf8t49l+uPpCg3lbnK+Hq59hg//25Iz7nEovzyyy8qQ5HETpiqH3J+hpAv0Lt27cq1nTl1kxw3IeclJ8maKEr62ieNAJGzfpDjnTcLoDmKu/629DGyNeyxsCH16tVTw3H69eunxi8aZ96Wf1S5qyu/k4ujMTgv750WU4Hfko7Nx8cn+7mk9pNKJy+5sy9p++QLuaRelcaNpGSV4Dq5wyN3jyRPtDGwrSCSgk7SAErOcJkrQlLNSqWT8y61kHzk8n4SrCU9NBKIJXMiSJCv5Dl/9NFHVaCfBGnJ58tYYrlzLjm2ZSmIBCpK178ssn3eO3VygZKLlQyPkmEDMsZYxirLkIC84/cljZ7sj2wv8QbSI2IqFbDEK8gQLPkSLu8rQ63kDp58sZdc6wXFxRQXGU4g50wqaGk0SUUicSRStsKSO58ye7Y0BOQukpRL7ijJUDL5nfQIWdMxIrIFMnxHrgUyd4EkaJBrm9ydl7loJFGCXIflppV8UZabSHnnF5IeXYktyEt6GaQXRG4SyZ1/SSstw4gklbd8ljRc7iZZiNQP8qVerllybZf9kOtHzvg7YzmkTjPWRXKdkd5TCU6fP3++qhflOifj7+W5xChKQ0OuPbeLhZCGhFwnpQdCjknedN2yf9JbIUHjUldIvSvvL/uaM/7RnLpJ9lWOn3yRly/ZkkZV6jyJ5ZB619T8S8VJ5g2SlMNy/TX2QC9btkw1rAqruOtvSx8jm8PUWLbn1KlThmHDhhnq1q1rcHV1Nbi5uRkaNGhgePHFF1Vatpxul242Zyo5Y+rRgpbFixdnp9Z79dVXDbVq1TI4OTkZPD09DZ06dTL8+uuvd7XvktZQUr5VqVJF7Xe7du1UOkFJYydL3tSDb775ZvZnSUq7J554wnD69OnsbXbu3KnSoEqq0pyp6/Kmq8tJPtNU6jqjr776SqValPR0clwlHZ+p9ztx4oShffv2qhzyO2Na1YLS90nqVHk/KYukJ5RzKMfzTuliTaVHLEhBr5fUfpIO0N3d3VC+fHnDCy+8YDhy5IjJdLOSIjYvU+WX1IuSnljKJMdf0ln26NHDEBISouljRKRnxv8tSbeal6RyrlOnjlrk/1fI9XTgwIHq+ir/d9WqVTM89NBDKkVt3tSjBS3bt29X20VERKjrqryHo6OjwdvbW73X7t2772rf5X/92WefNVSsWFGlAe/WrZu6hsj/dd601VevXjWMGDFCfZZcf/z8/NQ2V65cyd5m7dq1hkaNGql9yXmtK+haIalQ/f391bbvvfeeyd9/8MEH6rVSP0ga7nXr1pl8P3PqprS0NMPkyZOz6zrZh/Hjx+dKA3y7lO+m6k9TCnq9/A107txZlUmuuxMmTDBs3rzZZLrZu732Fnf9XVrHiAwGOzkIlm7cEBERERGRdWOMBRERERERFRkbFkREREREVGRsWBARERERUZGxYUFEREREREXGhgURERERERUZGxZERERERFRkNjdBnkzCJZPuyIQ35kwJT0SkZ5J5PD4+Xk1EKBNl2irWEUREha8fbK5hIY0Kf39/S+8GEZEmXbhwAX5+frBVrCOIiApfP9hcw0J6KowHx9PT06zXpqWlYdOmTejatSucnJxgrfRQDpZBO3gu9HEu4uLi1E0X4zXSVtl6HcEyaAfPhXbY+rmIM6N+sLmGhXH4k1QYhak03N3d1eus9Q9LL+VgGbSD50Jf58LWh4jaeh3BMmgHz4V28Fzcff1guwNpiYiIiIio2LBhQURERERE1t2wmDdvHpo1a5bd5dymTRv8+uuvt33NypUr0aBBA7i6uqJp06bYsGFDqe0vERGVDtYPRETWx6INC4ks//DDDxESEoJ9+/bhgQcewKOPPoqjR4+a3H7nzp3o168fBg8ejP3796N3795qOXLkSKnvOxERlRzWD0RE1seiDYuHH34YPXv2RL169VC/fn28//77KFOmDHbv3m1y+1mzZqF79+4YO3YsGjZsiClTpiAwMBBz5swp9X0nIqKSw/qBiMj6aCYrVEZGhhrmlJCQoIZEmbJr1y6MHj0617pu3bphzZo1Bb5vSkqKWnKmzDJG+MtiDuP25r5Oa/RQDpZBO3gutCEtIxPvrjuG+hmF+9/W8vWgpOoHIiJbsf3kFfxxyQ49DAZ9NywOHz6sKork5GTVW7F69Wo0atTI5LaXL1+Gj49PrnXyXNYXZOrUqZg8eXK+9ZLLV9ICFsbmzZuhB3ooB8ugHTwXlrXijD3+jrJHBRcHeDlvhqOZ/dGJiYnQmpKuHwRvPuXGGwXawXOhHdZ+Ls5fS8SoFYcQl+yA4L3h+G+rGma93pxyW7xhERAQgAMHDiA2NhY//vgjBg0ahL/++qvAysNc48ePz3UXyzjJh0wQUpgc5fLlqUuXLlabo1wv5WAZtIPnwvK+/yccf+86Ackw/p+amejRzfz/bWNvrpaUdP0gePPJNN4o0A6eC+2wxnORkgHMOOKAuGQ71ChjgHv0UWzYYDqWuThuPFm8YeHs7Iy6deuqx0FBQdi7d6+KpViwYEG+bX19fREVFZVrnTyX9QVxcXFRS15S6Rb2S3VRXqsleigHy6AdPBeWsf1kDN7bEKYej+lSD/43jxfqXGjxWlDS9YPgzafceKNAO3gutMNaz4XBYFA9FZGJUajg4Yzn6ieW+I0nizcs8srMzMwVE5GTdIlv2bIFo0aNyl4nJ7qgMbdERHp2JuYmhi8JRUamAY8FVsPz99fEr78eh16VRP3Am0+m8UaBdvBcaIe1nYv5f53GhiNRcLS3w5x+zRF9dFeJ33iyaMNC7hT16NED1atXR3x8PJYuXYqtW7fit99+U78fOHAgqlWrprqqxciRI9GhQwdMnz4dvXr1wrJly1Sa2oULF1qyGEREpS42MQ1Dvt2HuOR0BFYvhw/+0xR2yNTNmWD9QERUeNv+jcHHG0+ox28/0hjBNcrDzBFQhWLRhkV0dLRqPERGRsLLy0tNlieNCulqEuHh4bC3/38EYtu2bVXjY+LEiZgwYYJKUysZP5o0aWLBUhARla70jEyM+CEUZ64koKqXKxYMCIarkwPS0vTTsGD9QERUOOFXE/HyD/uRaQD6BPmhf+vqSE9PR2mwaMPiq6++uu3vpfcirz59+qiFiMhWvbf+uEod6ObkgC8GBaNS2fxxZNaO9QMRkfkSU9Px/OJ9iE1KQ3P/cpjSuwns7CS1hw1MkEdEROZZ+k84Fu08px7P6Nscjat68RASEREkWPuNnw7jxOV4VCzjjPn9A1Vvdmliw4KIyErsOn0Vk9YeUY/HdKmP7k2qWHqXiIhII77cfha/HLykgrU/fzoIVbzcSn0f2LAgIrKSMbPDloQgPdOAh5tXxYgHstKwEhER7Th5BVNvZQV866FGaFXL2yIHhQ0LIiKNi09Ow5Dv9uJGYhqa+Xlh2hPNSnXMLBERadeFa4kqoYcEaz8R5IeBbcybWbs4sWFBRKRhMkfFqGUH8G/UTfh4uuCLgVkZoIiIiJJSM/DC4pDsG0/vlXKwdl5sWBARadi038Kw5UQ0XBztsXBAMHw8XS29S0REpJFg7XGrDuFYZJyaWXt+/yCL33hiw4KISKNWhUaomVPFx080U6kDiYiIxFc7zmLtgUtwsLfD3KcDUbVc6Qdr58WGBRGRBu0Pv45xqw6rx8M71cGjLapZepeIiEgjdp6SYO2smbUn9mqIe2tXgBawYUFEpDGRsUl4fnEIUtMz0aWRD8Z0CbD0LhERkUZEXJdg7f0qBu+xwGp4pm1NaAUbFkREGpKcloHnvwtBTHwKGviWxcy+LWBvzwxQREQEVUdIsPa1hFQ0qeaJD/7TVFNZAtmwICLSUCDe2B8P4fDFWHh7OKsMUB4ujpbeLSIi0kgdMWHVYRy9FKfqCC0Ea+fFhgURkUZ8vvV0jllTA+Hv7W7pXSIiIo1YtPMcVu2/qIK15zzVEn7ltVdHsGFBRKQBm49F4ZNNYerx5EcbayYQj4iILG/3mat4b33WzNoTejZE2zoVoUVsWBARWVjY5XiMWrYfBgPUjKlPt7bcrKlERKQtF28kYfiSUBWs3btFVTzXTjvB2nmxYUFEZEHXE1Ix5Lu9SEjNQJvaFfDWQ414PoiIKDtYe9j3IbiakIpGVTwx9bFmmgrWzosNCyIiC0nLyMRLS0Jx4VoS/L3dVFyFkwMvy0REBBWs/ebqIzgUEYvy7k5YMCAIbs7aCtbOizUYEZGFvLfuGHaduQoPZwd8OfAelPdw5rkgIiLlu13n8VNoBCTj+JynrCOhBxsWREQW8MOecHy767x6PKNvCwT4luV5ICIi5Z8zVzFl3TH1eHyPhmhXV5vB2ppqWEydOhX33HMPypYti8qVK6N3794IC8vKilKQRYsWqbFlORdXV9dS22cioqLae+4aJq09oh6/1rU+ujb25UElIiIlMjYJw5eGIj3TgEeaV8WQ+2vBWli0YfHXX39h+PDh2L17NzZv3oy0tDR07doVCQkJt32dp6cnIiMjs5fz57Pu+hERWUN2jxcXhyAtw4BezapgeKe6lt4lIiLSULD2i4tDcOVmKhpW8cRHj2s7WFtTDYuNGzfimWeeQePGjdG8eXPVGxEeHo6QkJDbvk4OsK+vb/bi4+NTavtMRFRYSakZeGHxvuzsHtOesK4KozSxR5uIbDFY+601R3AwIhZebk5Y0F/7wdqajrGIjY1VP729vW+73c2bN1GjRg34+/vj0UcfxdGjR0tpD4mICl9hvPHTIRy5GAdvD2csHBgEd2dHHs4CsEebiGzN9/+EY2WIMVi7JapX0H6wdl6aqdUyMzMxatQotGvXDk2aNClwu4CAAHz99ddo1qyZaoh88sknaNu2rWpc+Pn55ds+JSVFLUZxcXHqpwy7ksUcxu3NfZ3W6KEcLIN28FzcnYXbz+Lng5fgaG+Hz/o2g08Zp2L/HyzKudDa9UB6tHOSHm2JxZMe7fbt29+xR5uIyNpi7yb/nHWj/I3uDXB/vUqwRpppWEisxZEjR7Bjx47bbtemTRu1GEmjomHDhliwYAGmTJlisjt98uTJ+dZv2rQJ7u6FawlKPIge6KEcLIN28FwU7Nh1Oyw8IR3EduhdIx1Xj+/GhuPaOheJiYnQMnN7tOVmVWBgID744AM13JaISKui4pLVnEYSrC2xd8+3rw1rpYmGxYgRI7Bu3Tps27bNZK/D7Tg5OaFly5Y4deqUyd+PHz8eo0ePztVjIUOoJEhcgsDNvaMnFXaXLl3U51orPZSDZdAOnovbO3slARMX/AMD0tE32A9THmlYYnEVRTkXxt5cLSqpHm3BXu3c2AOpHTwXtnEuUtIzVexdTHwKAnzK4P1HGiI9Pb3YP6e0erQdLT3m+OWXX8bq1auxdetW1KplfjqtjIwMHD58GD179jT5excXF7XkJZVuYb9UF+W1WqKHcrAM2sFzkV98chqGLT2A+OR0BNcojym9m8LZ0V6T50LL14KS6tEW7NU2jT2Q2sFzoe9zsey0PQ5E28PdwYAnq97AX1s2oSSVdI+2o6Uri6VLl2Lt2rVqLovLly+r9V5eXnBzc1OPBw4ciGrVqqmLv3j33Xdx7733om7durhx4wamTZum0s0OGTLEkkUhIsolM9OAV5cfwOmYBFTxcsW8/kGl0qjQm5Ls0Rbs1c6NPZDawXOh/3OxbG8Edu06BunEnvN0EO6vV3KT4JVWj7ZFGxbz5s1TPzt27Jhr/TfffKPS0ApJP2tv///K+Pr16xg6dKhqhJQvXx5BQUHYuXMnGjVqVMp7T0RUsBm//4vfj0fDxdEeCwYEoVLZ/D2nZNkebcFebdPYA6kdPBf6PBch56/j3fVZwXZjuwXggUZVUBpKukfb4kOh7kQqlJxmzJihFiIirfr1cCRm/5F1l3zqY03RzK+cpXfJ6rBHm4j0HKw97PusiVJ7NvXFsA51oBeaCN4mItKLE5fjMGblQfV48H218FigecN3KAt7tIlIj1LTM1WjIjo+BfV9ymDaE811NVEqGxZERMXkRmIqnv8uBImpGWhbpwLG92jAY1tI7NEmIj2a/MtRhIbfgKerIxYOCIaHi76+ijOSkIioGGRkGvDyD/sRfi0RfuXdMOepQDg68BJLRERZlu0Jx5J/wlWw9qz/tkTNih7QG9Z6RETFYNpvYdh+8gpcnezVXShvD2ceVyIiUkLDr2PS2qyZtV/rGoBODSpDj9iwICIqonWHLmH+X6fVYxkv26iqeZNvEhGRfkXHZwVrp2ZkontjX7zUUT/B2nmxYUFEVATHI+MwduUh9fiFDrXxcPOqPJ5ERJQdrD18SSii4lJQr3IZfPKkvoK182LDgoioCMHaLywOQVJahprY6PVuDNYmIqL/m7LuGPaeu46yLo5qTqMyOgvWzosNCyKiQgZrv7LsgArW9vd2w+x+LeFgr9+7UEREZJ4Vey9g8e7zWcHa/VqgdqUyuj+EbFgQERXC9E1h2PZvjArWXtA/GOXcGaxNRERZDly4gYlrjqjHr3aujwca+MAWsGFBRFSImbU/35oVrP3R480YrE1ERNli4lPw4uKsYO2ujXwwolNd2Ao2LIiIzHAyKh6v3ZpZe8h9tfBoi2o8fkREpKRlZAVrX45LRp1KHpj+ZHPY29AwWTYsiIjuUlxymgrWTrg1s/Y4zqxNREQ5vL/+OPacu6aCtBcODEZZVyebOj5sWBAR3YXMTANGLz+IM1cSUK1cVrA2Z9YmIiKjH0MisGjnOfV4Rt8WqGMDwdp5sWFBRHQX5vx5Cr8fj4Kzoz3m9Q9EhTIuPG5ERKQciriBCasPq8ejOtdDl0a2EaydFxsWRER38OeJaMz4/V/1+L3eTdDMrxyPGRERKVdu3grWTs9E54aV8coD9Wz2yLBhQUR0G+evJmDksv0wGICnW1fHk8H+PF5ERJQrWPtSbDJqV/LAp31b2FSwdl5sWBARFSApNQMvfh+KuOR0tKxeDpMebsRjRURE2T7YcBz/nL0VrD0gGJ42FqydFxsWREQmGAwGNV72eGQcKpZxxryng+Di6MBjRUREyqrQCHzzd1awtqSVrVvZ9oK182LDgojIhO92ncfq/RfhYG+HOU8FwtfLlceJiIiUIxdjMX5VVrD2Kw/URbfGvjwylm5YTJ06Fffccw/Kli2LypUro3fv3ggLC7vj61auXIkGDRrA1dUVTZs2xYYNG0plf4nINoScv4Yp646px+N7NMC9tStYepeIiEgjrt5MUXMapaRn4sEGlTGqc31L75JmWLRh8ddff2H48OHYvXs3Nm/ejLS0NHTt2hUJCQkFvmbnzp3o168fBg8ejP3796vGiCxHjhwp1X0nIn2Kjk/GS0tCkZ5pQK9mVTD4vlqW3iUiItKI9IxMjFi6HxdvJKFWRQZr5+UIC9q4cWOu54sWLVI9FyEhIWjfvr3J18yaNQvdu3fH2LFj1fMpU6aoRsmcOXMwf/78UtlvItJvdg+pMKLiUlCvchl8/Hgz2NnZbnYPIiLKbeqvJ7DrzFV4ODtgwYAgeLnZdrC2phoWecXGxqqf3t7eBW6za9cujB49Ote6bt26Yc2aNSa3T0lJUYtRXFyc+im9I7KYw7i9ua/TGj2Ug2XQDj2di483hmHP2WvwcHHA7P82h7O9warKVZRzobVyylDZVatW4cSJE3Bzc0Pbtm3x0UcfISAg4I5DZd966y2cO3cO9erVU6/p2bNnqe03EenX2gOX8NWOs9nB2vV9ylp6lzRHMw2LzMxMjBo1Cu3atUOTJk0K3O7y5cvw8ck9m6E8l/UFVU6TJ0/Ot37Tpk1wd3cv1L5KD4ke6KEcLIN2WPu52H/VDov+vaAe962RirC9f+HOEV/6OReJiYnQEuNQWYnDS09Px4QJE9RQ2WPHjsHDw+O2Q2Xluv/QQw9h6dKlaqhsaGjobesVIqI7iUgAPlubFXs3olNddG9ShQdNyw0LqUAkTmLHjh3F+r7jx4/P1cMhPRb+/v6qgvL09DT7jp5U2F26dIGTk/V2femhHCyDdujhXIRF3sDr8/9Rj4fcVxNvdKtvc+fC2JurFRwqS0RacS0hFV+FOahg7Y4BlfBqF+usI2ymYTFixAisW7cO27Ztg5+f32239fX1RVRUVK518lzWm+Li4qKWvKTSLeyXoKK8Vkv0UA6WQTus9VwkpKRj1MqjSMm0Q6ua5TGuR0M4Otjb3LnQ+rkriaGyRER3E6z96opDuJZih+rebpjVt6VKQ04abFjIBFQvv/wyVq9eja1bt6JWrTtnX2nTpg22bNmihk0ZyR06WU9EZO41aNyqwzgVkwBPJwNmPtnM6hsVelRSQ2UF4/D0GzNlzWXQSzn0UIYPN4Zh55lrKuZu9pNN4O5kneVJK6UYPEdLD3+SMbBr165Vc1kYL/5eXl4qWE8MHDgQ1apVU2NmxciRI9GhQwdMnz4dvXr1wrJly7Bv3z4sXLjQkkUhIiv07c5z+OXgJTja2+HZ+umoVDZ/7ybpd6isYByePmOm9FIGvZTDWssQesUO3550UI+frpuJcwd34dxBWLXNJRyDZ9GGxbx589TPjh075lr/zTff4JlnnlGPw8PDYW///zuIkhlEGiMTJ05UwXyS9UO6uRmYR0TmCA2/jvc3HFePX+9WHz43jvIAalBJDpUVjMPTX8yUHsqgl3JYcxmOR8bjjS8k9i4TQ9pVR9PMM1ZZjtKOwbP4UKg7kSFSefXp00ctRESFnTV1+JJQpGUY0KtpFTzTpjp+/ZUNCy0praGyjMPTV8yU3sqgl3JYWxmuJ6Ri+LIDSE7LxP31KuK1rgH4beMZqyuHJWLwNBG8TURUWjIyDRi1/AAiY5NRu5IHPny8KTgHnvZwqCwRWSpY+5Vl+3HhWhKqe7tjdj8Ga5uDUYpEZFNmbTmJ7SevwM3JAfP7B6Gsq3XffdIrGSormaBkqGyVKlWyl+XLl2dvI0NlIyMj8w2VlZi75s2b48cff+RQWSIyy7RNYdl1hMysXc7dmUfQDIXqsTh79iy2b9+O8+fPq4COSpUqoWXLlqq72dXVtTBvSURU4raGRWP2HyfV4w8ea8JZUzWMQ2WJqLStO3QJC/46ox5P69MMDauYN98ZmdmwWLJkCWbNmqWyMEkKv6pVq6rsTdeuXcPp06dVo+Lpp5/GG2+8gRo1avD4EpFmXLyRpIZASWjX062r4z8tbx8ITEREtuN4ZBzGrjykHr/QvjYealbV0ruk74aF9Eg4OzurbE0//fSTmr06by5wmZxI0r8GBwfj888/Z4A1EWlCanomXloSihuJaWjm54VJDzey9C7pGnu1icia3EhMxQuLQ5CUlqGCtV/v3sDSu6T/hsWHH36oZjC9XWYNGQsry/vvv49z584V1z4SERXJBxuO4+CFG/Byc8LcpwLh4piVl5yKF3u1icgaE3q8suwAwq8lwq+8Gz77L4O1S6VhcbtGRV4VKlRQCxGRpa0/FIlFO7NudHz6ZHP4e7tbepd0ib3aRGSNpm8Kw7Z/Y+DqZK+Ctct7MFi71LNCLVq0yOT69PR0NdkQEZEWnIm5iTd+yhozO6xjHTzY0MfSu6Rb0qv9zz//4KWXXso3VDZnr/b8+fNx4sQJ1K5d2yL7SURktOFwJD7felo9/ujxZmhc1YsHxxINi1deeUXFT1y/fj17XVhYGFq3bo0ffvihqPtERFRkSakZKq7iZko6WtXyxpgu9XlUS5C5vdpBQUE8H0RkMWGX4/HayoPq8dD7a+HRFtV4NizVsNi/fz8iIiLQtGlTNavp3LlzERgYiAYNGuDgwayTRERkSW//fAQnLsejYhlnzOnXEo4OnLantLBXm4i0LDYxDS8s3ofE1Ay0rVMBbzBYu9gUqqatU6cO/v77bzz22GPo3r07Xn31VXz55ZcqcM/Li91IRGRZK/ddwIp9EbC3gwrEq+zJ+XVKE3u1iUjLwdojl+/HuauJqFbODXOeCuSNp2JU6Ft469evV6llZVK8cuXK4auvvsKlS5eKc9+IiArVvf3W2iPq8aud66Nt3Yo8iqWMvdpEpFUzNv+LrWExcHHMCtb2ZrC25RsWL7zwgoqxkInwZAbuQ4cOqTkuZGjUihUrincPiYjuUkJKOoYtCUFyWiba16+E4Z3q8thZAHu1iUiLNh6JxJw/T6nHHz7eFE2qcZSNJhoWMgxKsn+MGTMGdnZ28PX1xYYNG/Duu+/iueeeK/adJCK6E4PBgAmrD+NMTAJ8PV0xs28L2MtYKLII9moTkZacjIrHmBVZccDPtauF/7T0s/Qu6VKhGhYhISFo3rx5vvXDhw9XvyMiKm0/7LmAtQcuwcHeDnOeasnubQtirzYRaUlsUhqeXxyChNQM3FvbG+N7cmZti0+QlzcfeUECAgKKsj9ERGY7cjEW7/xyVD1+vVsAgmt68yhakLFX23gDytirLRkEpVf7ySef5PkholKRmWnAq8sP4OyVBFT1csXcpwLhxCyBlu+xkOxPu3fvvuN28fHx+Oijj1QFQkRU0uKT0zBiaShS0zPxYIPKGHo/J16zNPZqE5FWzNxyEn+ciL4VrB2MCmUKvjlOpdhjIcHajz/+uEon+/DDDyM4OBhVq1aFq6urmijv2LFj2LFjh7or1atXL0ybNq0Ydo+I6PZxFeNWHc5OGzj9yeaMq9AA9moTkRb8dvQyPttyUj3+4D9N0dSPwdqa6bEYPHgwzpw5gwkTJqhGxPPPP4/7778f99xzj5px9YsvvkD16tWxd+9eLF++XD2+k23btqlGijRQJAh8zZo1t91+69ataru8y+XLl++2GESkI9/vPo/1hyLhaG+H2U+1RDl3Z0vvks1irzYRacmp6P8Haz/TtiYeD2KwtuZiLOQuVP/+/dUiYmNjkZSUhAoVKsDJycnsD09ISFBjcGXMrUy2d7fCwsLg6emZ/bxy5cpmfzYRWbfDEbGYsu64ejyuRwMEVi9v6V2yaezVJiKtiEvOCta+mZKO1rW88WavhpbeJZtRqOBtIxkWVZSZtnv06KEWc0lDQiblIyLbrTSGS1xFRia6NPLB4PtqWXqXbJ70astNp5UrV6pe64ULF6qbT0J6lhs1aqR6t6VXu2FDVvJEVHLB2qOXH1Cpx6tIsPbTDNbWbMPis88+M7leGhf169dXs3CXhhYtWiAlJQVNmjTBO++8g3bt2hW4rWwni1FcXJz6mZaWphZzGLc393Vao4dysAy2ey4kruL1lYcQfk3iKlwxtXcjpKenw9b/nopajuIoe3H3ahMRmeuzP07i9+PRcHa0x/z+QajIYG3tNixmzJhhcv2NGzdUBdK2bVv8/PPP8PYumVSPVapUwfz581XguDQWvvzyS3Ts2FGlNQwMDDT5mqlTp2Ly5Mn51m/atAnu7u6F2o/NmzdDD/RQDpbB9s7F9st22HjWAQ52BvT1u4m//yy+z9XD31Nhy5GYmFjs+1HUXm0iInNsPhaFmb9nBWu/37sJmvtzdIumGxZnz54t8HcS2C13qSZOnIjPP/8cJUHmyMg5T4Y0ZE6fPq0aPIsXLzb5mvHjx2P06NG5eiz8/f3RtWvXXHEad3tHTyrsLl26WPXdNz2Ug2WwzXNx9FIcXlv4j/Rb4I3uDfBs2xrF8r56+HsqajmMvblFUdy92pLgQzIMSvrayMhIrF69Gr17975tgo9OnTrlWy+vlbk0iEi/TsfcVEOgxKA2NdAn2N/Su2STihRjkVPt2rXx4YcfqkDs0tSqVSuV5vZ2XfOmUh9KpVvYLxBFea2W6KEcLIPtnAuJqxi54hDSMgzo3NAHQ9vXUWP3i5Me/p4KW47iKHdx92ozwQcR3e18Rs9/tw/xKeloVdMbEx9qxANn7Q0LISlmSzv164EDB9QQKSLSL4mrGP/TYZy/NV/FJ32aFXujgoquuHu1meCDiO4mWFvSyp6OSYCvpyvmPN2SM2vrpWFx+PBh1Khx90MTbt68iVOnTuWqlKShIHezpJEiw5guXryI7777Tv1+5syZqFWrFho3bozk5GQVY/HHH3+oeAki0q/v/wnH+sNZ81XM4XwVVqk0e7XNSfBBRNZt7p+nsOlYFJwd7DF/QBAql3W19C7ZNMfiGIMrXdwyBnbMmDEYNGjQXb/fvn37co2HNcZCyHssWrRIjYsNDw/P/n1qaqr6DGlsSOB1s2bN8Pvvv5scU0tE+nDkYiym/HJMPZa4ipacr8JqlXSvdmESfDBzoP4ypOmhDHopR0mX4c+wGHz6+7/q8TsPN0RjX48S+SxbPxdpZrzGrIaFzB1R0PADWT9kyBCMGzfurt9PLvgyxKEg0rjI6fXXX1cLEdnOuNkRt+areLBBZQy5n/NVWDNze7VLI8EHMwfqN0OaHsqgl3KURBmik4BPDzvAYLBDO59MeEQdxIYNWTNtlxRbPReJZmQNNKth8eeff5pcL9mV6tWrB1dXV0RHR6Nq1armvC0RUT5y02HC6iM4dzURVb1c8Umf5oyr0Lji7tUujQQfzByovwxpeiiDXspRUmWQGbX7LPgHSRkJCKpeDgufDVbzVpQUWz8XcWZkDTSrYdGhQ4fb/v7gwYOquzkjI8OctyUiyueHPRfwy8FLcLC3w+ynWqK8hzOPksYVd692aST4YOZA/WZI00MZ9FKO4iyDSuax7BBOxSTAx9MF8wYEwcMtf/bPkmCr58LJjO2LNXibiKg4HI+Mw+RfjqrHY7sFIKhGyUy6ScWruHu1meCDiPL6fOtpbDx6GU4OdpjXn8HaWsOGBRFpSkJKOoYvDUVKeiY6BlTC8/fXtvQukYV6tZngg4hy+jMsGp9sClOPJz/SBIFM5qE5bFgQkWZIF/fENUdw5lY+8k+fbAF7e85XYauY4IOIjM5dScDIH/ZDcv70a1UdT7WuzoNj7Q2LQ4cO3fb3YWFZrUgiosJYuS8Cq/dfVHEVn/VrCW/GVRAR2TzpyX5hcQjiktPRsno5vPMIZ9bWRcNCJh2SADxTKWKN6zkbLhEVxr9R8Zj08xH1eHSX+mhVi3EVRES2Tr5bvv7jIYRFxaNSWRfM7x8EF0cHS+8WFUfDQmbGJiIqbomp6Ri+JBTJaZm4v15FDOtQhwfZCrFXm4iK2/y/zmD94cisYO2nA+HjyZm1ddOwKMmJjYjIdr299ihORt9E5bIumNGXcRXWir3aRFSc/vo3Bh//dkI9fvvhxgiuyZ5sXTUsPv74Y7z88stwc3NTz//++28EBwerPOAiPj4eb7zxBj7//POS2Vsi0p2fQiKwMiQCEqM9678tUbFM6eQjp+LHXm0iKi7nrybglVvB2n2D/fE0g7X117CQGUqfeeaZ7IZFjx491ORDtWvXzp7ye8GCBWxYENFdORUdr7JAiVGd66NNnQo8claMvdpEVFzDYyVYOzYpDS38y+Hd3o0Zw2slzJr/PG/QtqkgbiKiu5GUmoHhS/YjKS0D7epWwPBOdXngdGT79u3o378/2rRpg4sXL6p1ixcvxo4dOyy9a0RkBcHaJy7Hqx7sef0DGayt14YFEVFxeefnoyrLh1QcM/u2VClmSR9++ukndOvWTfVu79+/HykpKWp9bGwsPvjgA0vvHhFp2Bfbz2DdoUg42svM2oGo4pU1SoasAxsWRFTqVoVGYPm+C7CzAz77bwuVQpD047333sP8+fPxxRdfwMnJKXt9u3btEBoaatF9IyLt2nHyCj781Ris3Qj3MFhb/zNvf/nllyhTpox6nJ6ejkWLFqFixYrZwdtERHeKq3hzdVZcxcgH66Ft3azrB+mHTJbavn37fOu9vLxw48YNi+wTEWnbhWuJGPFDKDINwJPBfuh/LzOR6r5hUb16dXUHysjX11eNmc27DRHRneIq2tapgJcfqMcDpUNSN5w6dQo1a9bMtV7iK4zJPoiIctYNzy8OwY3ENDT388K7jzZhsLYtNCzOnTtXcntCRLr39s9H/h9X8d8WjKvQqaFDh2LkyJH4+uuv1ZeDS5cuYdeuXRgzZgwmTZpk6d0jIo0Fa7/x0yEcj4xDxTLOmD8gCK5OnFnbJhoWycnJ+P333/HQQw9lp581BuWpN3N0xLvvvgtXV86KSET556tYsS9rvgqJq6hcltcJvRo3bhwyMzPx4IMPqjTkMixK5jsaO3YshgwZYundIyIN+WrHWfx88JIK1p77FIO1bSp4W+IpZJ4Kozlz5mDnzp0q64csMizKnMnxtm3bhocffhhVq1ZVd7XWrFlzx9ds3boVgYGBqpKqW7eu2ici0raTUf+fr2Lkg/UZV6Fzcj1/8803ce3aNRw5cgS7d+9GTEyMirGoVauWpXePiDRi56kr+GDDcfV4Yq+GaF2bcxnZVMNiyZIleP7553OtW7p0Kf7880+1TJs2DStXrrzr90tISEDz5s0xd+7cu57VtVevXujUqZOamG/UqFHq7tdvv/1mTjGIqJQnOnppSaiKq7ivbkWMeIDzVeiV9GBLT3ZwcLDKALVhwwY0atQIR48eRUBAAGbNmoVXX33V0rtJRBoJ1h6+NCtY+/FAPwxqmzsmi2xgKJQE4zVt2jT7uQx5srf/f9ukVatWGD58+F2/n8zcLcvdkvSFcrdr+vTp6nnDhg1VMOCMGTNUznQi0t7YWempOBl9U6WUndGXcRV6JvET0qvduXNn1Zvdp08fPPvss6rHQq7b8tzBgWOniWydBGvLzNrXE9PQzM8L7/+Hwdo22bCQNIE5YyqkazsnGVOb8/fFTYL/pMLKSRoU0nNBRNqzcl8EVoVeVHEVs/u15HwVOic91t999x0eeeQRNQSqWbNmKi35wYMHmeGFiLJvOE1YfRjHIuNQwcMZ8/szWNtmGxZ+fn6qspAubVMOHTqktikply9fho+PT6518jwuLg5JSUlqlte8pKGTs7Ej24q0tDS1mMO4vbmv0xo9lINl0P65OHE5Hm+tzYqrePXBugjy99Ts35we/p6KWo7iKHtERASCgoLU4yZNmqhYOBn6JDEXRETi67/PYfX+iyor4JynAlG1HGfWttmGRc+ePVVXt8Q55M38JF/sJ0+erH6nJVOnTlX7ldemTZvg7u5eqPfcvHkz9EAP5WAZtHkukjOA6YcckJJuh4blMuF38wQ2bMiaTVXL9PD3VNhySPamosrIyICzs3OuTIHGCVWJiHaezh2s3aYOg7VtumExYcIErFixQvVYjBgxAvXr18+eZVUyREmXt2xTkpMuRUVF5Vonzz09PU32VggJJBw9enSuHgt/f3907dpVvc7cO3pSYXfp0gVOTk6wVnooB8ug3XMh3dyjVhxCdHIUfD1d8O2wNijv/v8vm1qkh7+nopbD2JtbFHLun3nmGdVTYUxR/uKLL8LDwyPXdqtWrSryZxGRdbl4Iwkjlu5HRqYBj7WshmcYrK1LZjUsZNiRBOQNGzZM5SmXSkRIN7dUZJJqNu9QpeLUpk0blWUkJ6lEZX1BpIIzVnI5SaVb2C8QRXmtluihHCyD9s7For/PYsORKJWT/PP+QajslftLpZbp4e+psOUojnIPGjQo1/P+/fsX6f0kJblkGwwJCUFkZCRWr16N3r173zEludxMkkxUchNp4sSJqrFDRJaTnCbB2vtwLSEVTap54oPHmnKIpE6Z1bAQkpVp48aNKj+5ZIkSMp+Et7e32R9+8+bN7PcwppOVNLLyXtWrV1e9DRcvXlTBgELufEnPyOuvv47nnnsOf/zxh+pBWb9+vdmfTUTFLzT8Ot6/1c09oWdDBFYvz8NsQ7755ptifT9jSnK53j/22GN3nZJc6gpJj75lyxaVkrxKlSrMHEhkIXIPetLPx3DkYhy8Gayte2Y3LIzky7+kly2Kffv2qTkpjIxDluSul0x8J3eowsPDczVqpBEhwYCSD10Cxb/88ktWGEQaIHeiRiwJRVqGAT2b+uLZdsxJTkXDlORE1m/7ZTusPhd5K1i7JfzKFy6+lXTesCgOHTt2zB5OZYqpWbXlNTLLNxFph0xwNObHw7gUm4xaFT3w0ePN2M1Npa4wKcmZOVB/GdL0UAa9lGPnyWisPpc139kb3erjnupeVlkePZyLtFLKGmjRhgUR6cNvEfbYEXEVrk72mNc/EGVdrT9OgaxPYVKSM3OgfjOk6aEM1lyO6ynAJ4cckAk7BFXMROXrR7Fhw1FYM2s9F6WZNZANCyIqkm0nr+C3iKx5CqY+1hQNfM3LtkZkScwcqL8MaXoog7WXIyUtA/2+2oub6XGo5m7AwqEd4emee5oCa2LN56K0swayYUFEhRZxPRFjVh6GAXZ4qpUf/tOy5CbIJCqJlOTMHKjfDGl6KIM1lkPNrL3mGA5fjEM5NycMDkhSjQprKoNezoUlsgZmDXwjIipE+sBh34fiRlIaqnsYMKFHAx5DsihJPS6ZoMxJSU5Exev73eexMiQC9nbAzL7NUMF6OyqoENiwIKJC3ZGatPYIDl+MRXl3JzwbkAEXR15OqHhJSnJJQS5LzpTkxmyBMoxp4MCB2dtLmtkzZ86olOQnTpxQcytJSnLJJEhEJW/P2WuY/Msx9XhcjwZox5m1bQ6/CRCR2ZbtvYAV+27dkXqyGbzzz0FJVGSSkrxly5ZqMaYkl8eTJk1SzwtKSS69FDL/xfTp05mSnKiURMYm4aUlIUjPNOChZlUw9P7aPPY2iDEWRGSW/eHX8fbarMwer3ULQNs6FbAhjAeRih9TkhNZz9DYF78PxZWbqWjgWxYfP8GU47aKPRZEdNei45NVXEVqRia6NfbBsA51ePSIiGx8aKzcbDp44Qa83JywcEAw3J1539pWsWFBRHclNT0Tw5eE4nJcMupU8sAnfZpzEjwiIhu35J9wLN93QQ2Nnd2vJapX4MzatowNCyK6K++vP4a9566jjIsjFg4M5iR4REQ2bt85CdbOGhr7evcGaF+/kqV3iSyMDQsiuqMV+y7g213n1eMZfVugTqUyPGpERDbscmyyiqtIyzCgV9MqeKE9g7WJDQsiuoPQ8OuYuPqIejzywXro0siHx4yIyIalpGdg2JIQXLmZggAfBmvT/7HHgogKFBWXjBcXh6hg7a6NfFTDgoiIbNs7Px/F/vAb8HR1xIIBQfBwYbA2ZWHDgogKTB/4/OIQRMenoL5PGXzatwXsJTqPiIhs1tJ/wvHDnguwswM+69cSNSt6WHqXSEPYsCAik+kDx686nJ0+8IuBwSpom4iIbFfI+et4++esobGvdQ1Ax4DKlt4l0hg2LIgon3l/ncbq/RfhYG+Hz58ORI0KvCNFRGTrQ2OHfR+igrV7NPHFSx05jxHlx4YFEeWy6ehlTPstayrtdx5uhHZ1K/IIERHZ+DxG0qiQobH1KpfBNM5jRAVgw4KIsh27FIdRyw/AYAD631sdA9rU5NEhIrJxMldFaPgNlHXNmseIQ2OpIGxYEFF2N/fgb/ciMTUDbetUwNsPN+aRISKyccv2hKvZtVWw9n9bohaDtUnrDYu5c+eiZs2acHV1RevWrbFnz54Ct120aBHs7OxyLfI6Iiq8xNR0DPl2HyJjk1GnkgfmPR0EJwdNXB6IiMiC8xhNWps1s/bozvXRqQGDten2LP7NYfny5Rg9ejTefvtthIaGonnz5ujWrRuio6MLfI2npyciIyOzl/Pns2YEJiLzZWYa8OryAzh8MRbeHs74+pl74OXuxENJRGTDouOzgrVlHqNujX0wvFNdS+8SWQGLNyw+/fRTDB06FM8++ywaNWqE+fPnw93dHV9//XWBr5FeCl9f3+zFx4czARMV1vsbjuO3o1FwdrDHwgFBzABFRGTjJFh7+JJQRMWloG7lMpj+JOcxortj0cT0qampCAkJwfjx47PX2dvbo3Pnzti1a1eBr7t58yZq1KiBzMxMBAYG4oMPPkDjxqbHg6ekpKjFKC4uTv1MS0tTizmM25v7Oq3RQzlYhuKxaNd5fLXjrHr84WON0bxaWZv8v9BDGYpaDmsvOxEVnynrjmHvueso6+KobjgxWJusomFx5coVZGRk5OtxkOcnTpww+ZqAgADVm9GsWTPExsbik08+Qdu2bXH06FH4+fnl237q1KmYPHlyvvWbNm1SPSOFsXnzZuiBHsrBMhTewat2+OZf6bS0wyPVM+AQsR8bIvbzXOhAYf4vEhMTS2RfiMi6rNh7AYt3Zw0xn9G3BWpXKmPpXSIrYnVT6bZp00YtRtKoaNiwIRYsWIApU6bk2156QySGI2ePhb+/P7p27apiNcy9oycVdpcuXeDkZL1j0PVQDpahaPadv44li0JgQCaeauWHdx5qqIYY8lxY7/9EUf8vjL25RGS7Dly4gYlrsmbWfrVzfXRuxKHmZEUNi4oVK8LBwQFRUVG51stziZ24G1J5tmzZEqdOnTL5excXF7WYel1hv0AU5bVaoodysAzmC7scjxe+34+U9Ex0blgZ7z7aFI7FkAGK50I7CnMurP1aQERFExOfghcXZwVrd2nkg5cfYLA2WVnwtrOzM4KCgrBly5bsdRI3Ic9z9krcjgylOnz4MKpUqVKCe0qkDxHXEzHw638Ql5yOoBrlMbtfYLE0KoiIyHqlZWRi+NJQXI5LRu1KHvj0yeawty9cLzbZNot/o5BhSl988QW+/fZbHD9+HMOGDUNCQoLKEiUGDhyYK7j73XffVfERZ86cUelp+/fvr9LNDhkyxIKlINK+qzdTMPDrPSrLR73KZfDVoGC4OTtYereIbovzHBGVvPfXH8ees9dUkPbCAcEo68oeTLLSGIu+ffsiJiYGkyZNwuXLl9GiRQts3LgxO6A7PDxcZYoyun79ukpPK9uWL19e9Xjs3LlTpaolItPiktNUo+JMTAKqerniu8GtUM7dmYeLNM04z5GkIZfJU2fOnKnmOQoLC0PlyqYn6pLYOfm9UWFjh4hsxY8hEVi081x2sLaklyWy2oaFGDFihFpM2bp1a67nM2bMUAsR3Z2k1AwMXrQXRy/FoYKHMxYPaY0qXm48fKR5Oec5EtLAWL9+vcoMOG7cuNvOc0REd3Y4IhYTVh9Wj0c+WE/FVhBZfcOCiEpGSnoGXvg+JCsfuauj6qmow9SBZAVKY54jwbmO9Denix7KUBrluJqQiucX71OT4T0QUAkvta9Z7J/Fc2F78xyxYUGkU1JZvPR9KLb9GwM3JwcsevYeNK7qZendItLMPEeCcx2ZxjmC9H0uMjKBz4/bIzLOHpVdDejqGYmNGyNRUvTw96SXcmwu4XmO2LAg0mmGjxFLQ7HlRDRcHO1VoHZQDW9L7xaRpuY5EpzrKDfOEWQb5+L9DSdwKi4cHs4O+HZo6xKLq9DD35NeypFWSvMcsWFBpMNGxchl+7HpWBScHe3xxcBgtK1b0dK7RaS5eY4E5zoq+NhZ6xcoPZWhJMqxen8EFu0KV4+nP9kCDauVR0njubCdeY4snm6WiIp3+JP0VGw4fBnODvZYMCAI7etX4iEmq8N5joiK35GLsRj3U1aw9ohOddG9CRMdUPFijwWRTiSnZeClJaH440S06qmY3z8QnQJMp+QksgaSanbQoEEIDg5Gq1atVLrZvPMcVatWTcVJGOc5uvfee1G3bl3cuHED06ZN4zxHRLdcS0jFC4tDkJKeiU4BlfBql/o8NlTs2LAg0oHE1HRVYWw/eQWuTvZqgiP2VJC14zxHRMUj/Vbc3cUbSahZwR0z/9sSDpxZm0oAGxZEVu5GYiqeW7QXoeE34O7sgK8G3YM2dSpYereIigXnOSIqug9/PYGdp6+qOmLhwGB4uVl/7AlpExsWRFYsKi4ZA7/ag7CoeHi6OuKbZ+9h9iciIsq29sBFfLnjrHr8SZ/mqO9TlkeHSgwbFkRW6nTMTTzzzR5cuJaEymVdsHhwawT4ssIgIqIsRy/F4o2fDqnHL3Wsg55Nq/DQUIliw4LICu09dw1Dv9uHG4lpqFHBHd8Pbg1/b3dL7xYREWnE9VvB2slpmehQvxLGdA2w9C6RDWDDgsjKrDt0CaNXHFSpZVv4l8OXg4JRsYyLpXeLiIg0FKz98g/7EXE9CdW93fEZg7WplLBhQWQlMjMNmLXlpFpEt8Y+mNm3JdycHSy9a0REpCHTfgvDjlNX4OYkwdpB8HJnsDaVDjYsiKxAQko6xqw4iI1HL6vnz7WrhTd7NWS6QCIiyuXng5ewYNsZ9Xhan2Zo4OvJI0Slhg0LIo07dyUBL34fghOX4+HkYIf3ezfFk/f4W3q3iIhIY45HxuH1Hw+qxy92qIOHmlW19C6RjWHDgkjDNh6JxNiVhxCfkq7iKBYMCGQ6WSIiMjmn0fOL96lg7fvrVcTYbgzWptLHhgWRBqWkZ+DjjWH46lbu8XtqlsfsfoHw9XK19K4REZHGZGQaVLC2pB/393ZjsDZZDBsWRBpzKjoer/xwAMci49Tz59vXVneenBzsLb1rRESk0WDt7SdvBWsPCEZ5D2dL7xLZKE18U5k7dy5q1qwJV1dXtG7dGnv27Lnt9itXrkSDBg3U9k2bNsWGDRtKbV+JSjLr03e7zqHXZztUo6K8uxMWDgjChJ4N2aggIiKT1h+KxPy/TqvHHz3RDA2rMFibbLhhsXz5cowePRpvv/02QkND0bx5c3Tr1g3R0dEmt9+5cyf69euHwYMHY//+/ejdu7dajhw5Uur7TlScAdr9vtiNSWuPIiU9a3zsb6Pao2tjXx5kIiIy6cTlOLy28mB27/YjzRmsTTbesPj0008xdOhQPPvss2jUqBHmz58Pd3d3fP311ya3nzVrFrp3746xY8eiYcOGmDJlCgIDAzFnzpxS33eiosrIBL7ccQ7dZ23DP2evqW7stx9uhG+fbYXKnoynICIi02IT09TM2klpGbivbkW8zmBtsvUYi9TUVISEhGD8+PHZ6+zt7dG5c2fs2rXL5GtkvfRw5CQ9HGvWrDG5fUpKilqM4uKyxq2npaWpxRw/hVzA4Wg7JIdegIuTk5pDwFEWBzv12NnBXj2XsfBZix2cHO3VemdHe7jcWmQbOzs7WIqx3OaWX0v0UIbt/0bj40MOuJz0r3retrY3pjzaSM2SmpGRjowMWAU9nAs9lKGo5bD2shPZWrD2K8v24/zVRPiVd8Psfi3hyDg8svWGxZUrV5CRkQEfH59c6+X5iRMnTL7m8uXLJreX9aZMnToVkydPzrd+06ZNqmfEHJP3OCApwwFLTh9HUdjBACd7ZC/Osjjc+mlvgIsDshZ7wMURcHUwwNVBfgJusjga1E93R3mc9brCtFM2b94Ma2eNZYhJAtZdsMeBq9JhaAcPRwMeqZGJ1pWicWR3NKx1UJ81ngs9lqGw5UhMTCyRfSGi4vfp5jD89W8MXJ3ssWBAEIO1STN0nxVKekNy9nBIj4W/vz+6du0KT0/zApw2xO5H+KUolCtfAQYA6ZkGtcidg7QMA9IzMtXPtIxMtV5+pqZnIvXWeiMD7JCaCbXkZ34LQXpDyrk5qaW8hxO83Z3h7eGMCh7O8C7jjIoezqhU1gUVyzijclkXOCBTffHo0qULnJycYI3k7qq1leHKzRTM+fMMlh+KUH8f9nZAO59MfDygPSp6mtfI1RJrPBd6LENRy2HszSUibfv1cCTm/nkrWPvxZmhc1cvSu0SkjYZFxYoV4eDggKioqFzr5bmvr+mgVVlvzvYuLi5qyUsqXXMr3jn9WqoMVD173mP2ayXjjzQwUtIy1RwFMoFNsvqZgaTUDCSmZSA5NQMJqfI8Xf1MSEnHzZR09TM+2bikqZ+xSWlqkS+o0niJjk9Ry93wdHWEu50DVsYcQtVybvD1ckNVL1f1WJZq5dzgJl0oVqAw57G0RcYm4YttZ/HDnnA1FlZ0qF8JYzrXxdn921WjQutl0Mu5sIUyFLYceig3kd79GxWPMbeCtYfcVwuPtqhm6V0i0k7DwtnZGUFBQdiyZYvK7CQyMzPV8xEjRph8TZs2bdTvR40alb1O7tDJei2zt7eDq70DXJ3kC3vxVOAGgwGJqRm4npiKG4lp6ue1hP8vV27KkoKrN1MQczMF0XEpKuNQXHI64mCHy6euFvje0rtRrby7GrspY/79y7urnzUquKvGh8SU0O0dj4zDor/PYdX+iOweqxb+5fBG9wZoU6eCurt8dj+PIhER3ZncTHz+u32q3m9bpwLG9WjAw0aaY/GhUDJMadCgQQgODkarVq0wc+ZMJCQkqCxRYuDAgahWrZqKlRAjR45Ehw4dMH36dPTq1QvLli3Dvn37sHDhQtgaCQD3cHFUi1/5u2uIxKek4+LVm/jl9+2o0bAZYm6m4VJsMi7HJuPSjSRcvJ6ktslqlKTi4IUb+d5HgtKloSGNjJoVPVArx1LVy001omyV9EBtPhaFxbvPY8/Za9nrW9fyxogH6qrMHZYM3CciIusjQ65HLduPc1cT1aiCOU8FMlibNMniDYu+ffsiJiYGkyZNUgHYLVq0wMaNG7MDtMPDw1WmKKO2bdti6dKlmDhxIiZMmIB69eqpjFBNmjSxYCmsg3yh9XR1glvlMggoZ0DPltVMDn+QuyIR1xNx4VrSrZ+JOH8tEeHXEhFxLUkN6TpzJUEtCIvJF+9Rq4IHale6tVQsgzqVy6jH8tl6veCHhl/H6v0Xse7gJdUjJKRXp3tjXzx3X00E1fC29G4SEZGVmvn7v/gzLEZllpRgbYmjJNIiizcshAx7Kmjo09atW/Ot69Onj1qoZHi5OcHLzctkQJh8ib4cl4zzVxJw9mqCmtjt7JVEnL1yUzU8JN4jLCpeLXlVLOOiGhh1bjU4pIdDnvt7u1vdzNIS9/LP2auqd2LzsWg15Myoipcrngjyw9Ota8DXi3NREBXF3LlzMW3aNHXjSSZQnT17turdLsjKlSvx1ltv4dy5c+rG00cffYSePXvyJJDV2nQsCrP/OKUef/h4UzSpxmBt0i5NNCzIeshdeOmGlaVt3Yq5fidZsS7eSMKZmAScjrmZ1ashP2MSVGC5fPmWJecQIeN7+pd3U8OqalbwUEOsZKnu7aFiPLLiUixLYlYOXLiO/eE3sPvMVfVTAueNyro6oksjHzwR6Id7a1ew6eFgRMVl+fLlarisTJzaunVrNVRW5i0KCwtD5cqV822/c+dO9OvXTw2dfeihh1TvtsTvhYaGslebrNLFBGDuT1lJyJ9rVwv/aeln6V0iui02LKjYyOQ8NVTDwAOdGuSu9CWb1VnV0LjV2Lj1WNZJpiQZNyoLkHtolZAUudXKZzVmVBYrT1dU9HDEmTioyYF8y3vAw9mhyLELkh5YYk0uXE9ExPUk1Tg6GXVTZeGQ53lJMHv7+hXRrbEvWteqoIaBEVHx+fTTTzF06NDsmDtpYKxfvx5ff/01xo0bl2/7WbNmoXv37hg7dqx6PmXKFJXcY86cOeq1RNZCskfO/eM05h52QIYhA/fW9saEngzWJu1jw4JKRVlXJzTzK6eWvAHlUXEpOHPlpmoknLs1vCr8WhLCryaotLvGVLrSS5D3z3fW0R3qkXyp97o1l4f0Hrg7y+IAFycHNdO5MYuVpP3NMBhUkLVk1pAhTTeS0nD1ZqqKLbkdGcLVwr88gmuWR7s6FVG9gvXOPUGkdampqQgJCVFzERlJvF3nzp2xa9cuk6+R9TnnLRLSwyFxeAVJSUlRS975PCRrmzmzke84dRXrDl3CxYv22LbqcK7YQGsimRlZBssLOX8dZ67IzTY73FfHG9P7NIMhMwNpmVkpy62F8X/InP8lLdJDOdKKUAZzXsOGBVmU9DJIHIIsbesgX6NDhiBdvJWtSn5eupGMqLhkNTfE+ajrSMx0QFJa1kSEMfEpaikKaaD4yVAvGZpVwQP1fcqgnk9ZNPT1hJe7PoPPibToypUryMjIyE7kYSTPT5w4YfI1EodhantZXxAZNjV58uR86zdt2gR397u/ebA10g6rz8mwTXsgOhLWjWXQgrJOBjxWMxMtK0Rj91+/w5pJz6Ee6KEcmwtRhsREaeTeHTYsSNONjgplXNSSt6dDWs9ZkxV2Q2qmnZrDQ00amJim0uXKpIMJqemqwWGcGV1IjLi9nZ2K2/BwcVA9G5KtqlJZmancRfV6MD6CyHZIj0jOXg7psfD390fXrl3h6el51+/jFxGLGidjcOrUSdStWw8OVtpjkZGZyTJogKSR79GoIvbs2IouXbpY7QSWUlfLF1lrLoNeypFWhDIYe3LvBhsWZPXMmcuDiKxDxYoV4eDggKioqFzr5bmvr6/J18h6c7YXLi4uainq7OVBtSqimZ8XNiT9i56d6lr1lw+WQRuMw0/M/VvUIj2UQS/lcCpEGczZ3jpvqRARka45OzsjKCgIW7ZsyTX+X563adPG5Gtkfc7thdyhK2h7IiIqXuyxICIiTZIhSoMGDUJwcLCau0LSzSYkJGRniRo4cCCqVaum4iTEyJEj0aFDB0yfPh29evXCsmXLsG/fPixcuNDCJSEisg1sWBARkSb17dsXMTExmDRpkgrAbtGiBTZu3JgdoB0eHp4r+1Lbtm3V3BUTJ07EhAkT1AR5khGqSZMmFiwFEZHtYMOCiIg0a8SIEWoxZevWrfnW9enTRy1ERFT6GGNBRERERERFxoYFEREREREVmc0NhZJJ18zNyZsz9ZtMEiKvteZ0Y3ooB8ugHTwX+jgXxmui8Rppq2y9jmAZtIPnQjts/VzEmVE/2FzDIj4+Xv2UCZCIiCj/NdLLy8tmDwvrCCKiwtcPdgYbuz0ledAvXbqEsmXLqpmdzWGckfXChQtmzciqNXooB8ugHTwX+jgXUhVIpVG1atVcmZZsja3XESyDdvBcaIetnwuDGfWDzfVYyAHx8/Mr0nvICbHWPyy9lYNl0A6eC+s/F7bcU2HEOiIL/5+1g+dCO2z5XHjdZf1gu7eliIiIiIio2LBhQURERERERcaGhRlcXFzw9ttvq5/WTA/lYBm0g+dCO/RwLqyZHo4/y6AdPBfawXNx92wueJuIiIiIiIofeyyIiIiIiKjI2LAgIiIiIqIiY8OCiIiIiIiKjA2LQnrkkUdQvXp1uLq6okqVKhgwYICaVMmanDt3DoMHD0atWrXg5uaGOnXqqMDD1NRUWJP3338fbdu2hbu7O8qVKwdrMXfuXNSsWVP9DbVu3Rp79uyBNdm2bRsefvhhNWGOTCS2Zs0aWJupU6finnvuUZOhVa5cGb1790ZYWBisybx589CsWbPs3ORt2rTBr7/+aundsnnWXkfopX6w1jqC9YPl6aF+sEQdwYZFIXXq1AkrVqxQf2Q//fQTTp8+jSeeeALW5MSJE2qW2QULFuDo0aOYMWMG5s+fjwkTJsCaSEXXp08fDBs2DNZi+fLlGD16tKqoQ0ND0bx5c3Tr1g3R0dGwFgkJCWq/pQK0Vn/99ReGDx+O3bt3Y/PmzUhLS0PXrl1V2ayFTPj54YcfIiQkBPv27cMDDzyARx99VP1Pk+VYex2hl/rBGusI1g/aoIf6wSJ1hGSFoqJbu3atwc7OzpCammrVh/Pjjz821KpVy2CNvvnmG4OXl5fBGrRq1cowfPjw7OcZGRmGqlWrGqZOnWqwRnIpWb16tcHaRUdHq7L89ddfBmtWvnx5w5dffmnp3SCd1RHWXD9YUx3B+kGb9FI/lHQdwR6LYnDt2jUsWbJEdbU6OTnBmsXGxsLb29vSu6FrcvdM7hx07tw5e529vb16vmvXLovum62Tv39hrf8DGRkZWLZsmbqjJt3dpA16qSNYP5Q81g/aZe31Q2nVEWxYFMEbb7wBDw8PVKhQAeHh4Vi7di2s2alTpzB79my88MILlt4VXbty5Yr65/bx8cm1Xp5fvnzZYvtl62TYx6hRo9CuXTs0adIE1uTw4cMoU6aMmsTpxRdfxOrVq9GoUSNL75bN01MdwfqhdLB+0CZrrh9Ku45gwyKHcePGqSDU2y0y7tRo7Nix2L9/PzZt2gQHBwcMHDhQhpbB2sohLl68iO7du6txqEOHDoU1loGoKGQs7ZEjR9TdHGsTEBCAAwcO4J9//lHjyAcNGoRjx45Zerd0Rw91hB7qB8E6gkqTNdcPpV1HcObtHGJiYnD16tXbHrDatWvD2dk53/qIiAj4+/tj586dFh+CYG45JFNJx44dce+992LRokVqWI41ngvZd7mjcOPGDWi9q1uyk/z4448qy4SR/KPLvlvjXU35MiJ3QHKWx5qMGDFCHXfJdCVZcKydDKuTLD4SeEvFRw91hB7qBz3XEawftEdv9UNJ1xGOxf6OVqxSpUpqKWw3mUhJSYE1lUPuREn2kqCgIHzzzTeaqTSKci60Tio6Od5btmzJ/iIufz/yXC5gVHrk7vHLL7+sGkVbt27VTaUhf09auBbpjR7qCD3UD3quI1g/aIde64eSriPYsCgE6Urau3cv7rvvPpQvX16lEXzrrbdU68/SvRXmkEpD7kTVqFEDn3zyiboDZOTr6wtrIWOXJThSfkrsgnT3ibp166oxhVokqWalhyI4OBitWrXCzJkzVTDVs88+C2tx8+ZNNe7a6OzZs+rYS2Cb5O+3lu7tpUuXqrtRkqvcGOPi5eWlcvdbg/Hjx6NHjx7qmMfHx6vySCX422+/WXrXbJYe6gi91A/WWEewftAGPdQPFqkjSiTXlM4dOnTI0KlTJ4O3t7fBxcXFULNmTcOLL75oiIiIMFhb6j35EzC1WJNBgwaZLMOff/5p0LLZs2cbqlevbnB2dlbpBXfv3m2wJnJ8TR13OR/WoqC/f/nfsBbPPfecoUaNGurvqFKlSoYHH3zQsGnTJkvvlk3TQx2hl/rBWusI1g+Wp4f6wRJ1BGMsiIiIiIioyLQzYJKIiIiIiKwWGxZERERERFRkbFgQEREREVGRsWFBRERERERFxoYFEREREREVGRsWRERERERUZGxYEBERERFRkbFhQURERERERcaGBRERERERFRkbFkREREREVGRsWBARERERUZGxYUFUymJiYuDr64sPPvgge93OnTvh7OyMLVu28HwQEdko1g9k7ewMBoPB0jtBZGs2bNiA3r17qwZFQEAAWrRogUcffRSffvqppXeNiIgsiPUDWTM2LIgsZPjw4fj9998RHByMw4cPY+/evXBxceH5ICKycawfyFqxYUFkIUlJSWjSpAkuXLiAkJAQNG3alOeCiIhYP5DVYowFkYWcPn0aly5dQmZmJs6dO8fzQERErB/IqrHHgsgCUlNT0apVKxVbITEWM2fOVMOhKleuzPNBRGTDWD+QNWPDgsgCxo4dix9//BEHDx5EmTJl0KFDB3h5eWHdunU8H0RENoz1A1kzDoUiKmVbt25VPRSLFy+Gp6cn7O3t1ePt27dj3rx5PB9ERDaK9QNZO/ZYEBERERFRkbHHgoiIiIiIiowNCyIiIiIiKjI2LIiIiIiIqMjYsCAiIiIioiJjw4KIiIiIiIqMDQsiIiIiIioyNiyIiIiIiKjI2LAgIiIiIqIiY8OCiIiIiIiKjA0LIiIiIiIqMjYsiIiIiIioyNiwICIiIiIiFNX/AKMPFqA/LTS5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "gelu, relu = GELU(), nn.ReLU()\n",
    "\n",
    "# Some sample data\n",
    "x = torch.linspace(-3, 3, 100)\n",
    "y_gelu, y_relu = gelu(x), relu(x)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "for i, (y, label) in enumerate(zip([y_gelu, y_relu], [\"GELU\", \"ReLU\"]), 1):\n",
    "    plt.subplot(1, 2, i)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(f\"{label} activation function\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(f\"{label}(x)\")\n",
    "    plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d8fe0f-58f0-4324-ac71-1eb84e98d64c",
   "metadata": {},
   "source": [
    "As we can see in the resulting plot, ReLU is a piecewise linear function that outputs the input directly if it is positive; otherwise, it outputs zero. GELU is a smooth, nonlinear function that approximates ReLU but with a non-zero gradient for negative values.\n",
    "\n",
    "The smoothness of GELU, as shown in the above figure, can lead to better optimization properties during training, as it allows for more nuanced adjustments to the model's parameters. In contrast, ReLU has a sharp corner at zero, which can sometimes make optimization harder, especially in networks that are very deep or have complex architectures.\n",
    "\n",
    "Moreover, unlike RELU, which outputs zero for any negative input, GELU allows for a small, non-zero output for negative values. This characteristic means that during the training process, neurons that receive negative input can still contribute to the learning process, albeit to a lesser extent than positive inputs.\n",
    "\n",
    "Next, let's use the GELU function to implement the small neural network module, FeedForward, that we will be using in the LLM's transformer block later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61d5ce08-3f7f-4d72-9a82-0d3b3dca7f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "658ee5ba-6d54-4916-b1f3-b6befa4df164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "print(GPT_CONFIG_124M[\"emb_dim\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb991b21-edd4-46aa-b703-4d32a09e6419",
   "metadata": {},
   "source": [
    "As we can see in the preceding code, the FeedForward module is a small neural network consisting of two Linear layers and a GELU activation function.\n",
    "\n",
    "In the 124 million parameter GPT model, it receives the input batches with tokens that have an embedding size of 768 each via the GPT_CONFIG_124M dictionary where GPT_CONFIG_124M[\"emb_dim\"] = 768.\n",
    "\n",
    "Let's use the GELU function to implement the small neural network module, FeedForward, that we will be using in the LLM's transformer block later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80624a2c-6569-47ce-bda1-3aaec15f127a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 768])\n"
     ]
    }
   ],
   "source": [
    "ffn = FeedForward(GPT_CONFIG_124M)\n",
    "x = torch.rand(2, 3, 768) #A\n",
    "out = ffn(x)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ff21c-867b-4244-94a9-0f1ac1fd03dc",
   "metadata": {},
   "source": [
    "The FeedForward module we implemented in this section plays a crucial role in enhancing the model's ability to learn from and generalize the data. \n",
    "\n",
    "Although the input and output dimensions of this module are the same, it internally expands the embedding dimension into a higher-dimensional space through the first linear layer. This expansion is followed by a non-linear GELU activation, and then a contraction back to the original dimension with the second linear transformation. Such a design allows for the exploration of a richer representation space.\n",
    "\n",
    "Moreover, the uniformity in input and output dimensions simplifies the architecture by enabling the stacking of multiple layers, as we will do later, without the need to adjust dimensions between them, thus making the model more scalable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bf547f-2533-4f51-be6b-54b449a4555b",
   "metadata": {},
   "source": [
    "## 4. Implementing Shortcut Connections\n",
    "\n",
    "Let us see how we can add shortcut connections to the forward method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2e3efbd-6cbe-4a73-b905-61873bebed54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleDeepNeuralNetwork(nn.Module):\n",
    "    def __init__(self, layer_sizes, use_shortcut):\n",
    "        super().__init__()\n",
    "        self.use_shortcut = use_shortcut\n",
    "        self.layers = nn.ModuleList([\n",
    "            nn.Sequential(nn.Linear(layer_sizes[0], layer_sizes[1]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[1], layer_sizes[2]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[2], layer_sizes[3]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[3], layer_sizes[4]), GELU()),\n",
    "            nn.Sequential(nn.Linear(layer_sizes[4], layer_sizes[5]), GELU())\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            # Compute the output of the current layer\n",
    "            layer_output = layer(x)\n",
    "            # Check if shortcut can be applied\n",
    "            if self.use_shortcut and x.shape == layer_output.shape:\n",
    "                x = x + layer_output\n",
    "            else:\n",
    "                x = layer_output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bf3f96-979e-4f73-a0f8-6b2dfca6cad2",
   "metadata": {},
   "source": [
    "The code implements a deep neural network with 5 layers, each consisting of a Linear layer and a GELU activation function. In the forward pass, we iteratively pass the input through the layers and optionally add the shortcut connections if the self.use_shortcut attribute is set to True.\n",
    "\n",
    "Let's use this code to first initialize a neural network without shortcut connections. Here, each layer will be initialized such that it accepts an example with 3 input values and returns 3 output values. The last layer returns a single output value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82308e2a-c177-4d2e-88a6-fa0e1129d4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_sizes = [3, 3, 3, 3, 3, 1]\n",
    "sample_input = torch.tensor([[1., 0., -1.]])\n",
    "torch.manual_seed(123) # specify random seed for the initial weights for reproducibility\n",
    "\n",
    "model_without_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aaaef4-0b14-41ed-b62e-d05b6cfc5efe",
   "metadata": {},
   "source": [
    "Next, we implement a function that computes the gradients in the the model's backward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc89a6c9-4b74-4120-b589-955e7d0d76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gradients(model, x):\n",
    "    # Forward pass\n",
    "    output = model(x)\n",
    "    target = torch.tensor([[0.]])\n",
    "\n",
    "    # Calculate loss based on how close the target\n",
    "    # and output are\n",
    "    loss = nn.MSELoss()\n",
    "    loss = loss(output, target)\n",
    "    \n",
    "    # Backward pass to calculate the gradients\n",
    "    loss.backward()\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            # Print the mean absolute gradient of the weights\n",
    "            print(f\"{name} has gradient mean of {param.grad.abs().mean().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1000a0-f62e-41b5-b250-033401d62ee2",
   "metadata": {},
   "source": [
    "In the preceding code, we specify a loss function that computes how close the model output and a user-specified target (here, for simplicity, the value 0) are. Then, when calling loss.backward(), PyTorch computes the loss gradient for each layer in the model. We can iterate through the weight parameters via model.named_parameters().\n",
    "\n",
    "Suppose we have a 3Ã—3 weight parameter matrix for a given layer. In that case, this layer will have 3Ã—3 gradient values, and we print the mean absolute gradient of these 3Ã—3 gradient values to obtain a single gradient value per layer to compare the gradients between layers more easily. In short, the .backward() method is a convenient method in PyTorch that computes loss gradients, which are required during model training, without implementing the math for the gradient calculation ourselves, thereby making working with deep neural networks much more accessible.\n",
    "\n",
    "Let's now use the print_gradients function and apply it to the model without skip connections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fff923e4-51d2-4c5d-b052-8d340e60da41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.00020173587836325169\n",
      "layers.1.0.weight has gradient mean of 0.0001201116101583466\n",
      "layers.2.0.weight has gradient mean of 0.0007152041653171182\n",
      "layers.3.0.weight has gradient mean of 0.001398873864673078\n",
      "layers.4.0.weight has gradient mean of 0.005049646366387606\n"
     ]
    }
   ],
   "source": [
    "print_gradients(model_without_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea0380a-030d-4a02-8e93-d4bcfe33e2b6",
   "metadata": {},
   "source": [
    "As we can see based on the output of the print_gradients function, the gradients become smaller as we progress from the last layer (layers.4) to the first layer (layers.0), which is a phenomenon called the vanishing gradient problem.\n",
    "\n",
    "Let's now instantiate a model with skip connections and see how it compares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87093325-75d7-40a9-bf46-448ec4aa9a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.0.weight has gradient mean of 0.2216978669166565\n",
      "layers.1.0.weight has gradient mean of 0.20694100856781006\n",
      "layers.2.0.weight has gradient mean of 0.3289698660373688\n",
      "layers.3.0.weight has gradient mean of 0.2665731906890869\n",
      "layers.4.0.weight has gradient mean of 1.3258538246154785\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model_with_shortcut = ExampleDeepNeuralNetwork(\n",
    "    layer_sizes, use_shortcut=True\n",
    ")\n",
    "print_gradients(model_with_shortcut, sample_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a190777-5d6e-4a1a-a67a-959eeb3d8006",
   "metadata": {},
   "source": [
    "As we can see, based on the output, the last layer (layers.4) still has a larger gradient than the other layers. However, the gradient value stabilizes as we progress towards the first layer (layers.0) and doesn't shrink to a vanishingly small value.\n",
    "\n",
    "In conclusion, shortcut connections are important for overcoming the limitations posed by the vanishing gradient problem in deep neural networks.\n",
    "\n",
    "Shortcut connections are a core building block of very large models such as LLMs, and they will help facilitate more effective training by ensuring consistent gradient flow across layers when we train the GPT model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a267c89f-f961-4e92-bdd3-b2e8d9471e02",
   "metadata": {},
   "source": [
    "## 5. Implementing Transformer Block in LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79017d6b-3c09-45f1-9ef8-87e8447d9660",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fbacb2-33bf-4943-a6ba-52212698fbec",
   "metadata": {},
   "source": [
    "### Demo: Implementing the Building Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe7f06d-2bd1-4793-bf76-1c34ba9fcb92",
   "metadata": {},
   "source": [
    "#### 1. Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df7f190f-e88c-4c6e-adae-890cc824c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
    "        super().__init__()\n",
    "        assert (d_out % num_heads == 0), \\\n",
    "            \"d_out must be divisible by num_heads\"\n",
    "\n",
    "        self.d_out = d_out\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_out // num_heads # Reduce the projection dim to match desired output dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
    "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\n",
    "            \"mask\",\n",
    "            torch.triu(torch.ones(context_length, context_length),\n",
    "                       diagonal=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, num_tokens, d_in = x.shape\n",
    "\n",
    "        keys = self.W_key(x) # Shape: (b, num_tokens, d_out)\n",
    "        queries = self.W_query(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
    "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
    "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim) \n",
    "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
    "\n",
    "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        queries = queries.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "\n",
    "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
    "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
    "\n",
    "        # Original mask truncated to the number of tokens and converted to boolean\n",
    "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
    "\n",
    "        # Use the mask to fill attention scores\n",
    "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
    "        \n",
    "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
    "        context_vec = (attn_weights @ values).transpose(1, 2) \n",
    "        \n",
    "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
    "        context_vec = context_vec.contiguous().view(b, num_tokens, self.d_out)\n",
    "        context_vec = self.out_proj(context_vec) # optional projection\n",
    "\n",
    "        return context_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363f8ab7-f9be-4f38-b682-b268ad10117d",
   "metadata": {},
   "source": [
    "#### 2. Layer Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b2c2ed70-ac2e-43c5-935e-7023ed16ebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, emb_dim):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(dim=-1, keepdim=True)\n",
    "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
    "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        return self.scale * norm_x + self.shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c92d3-86e7-47d7-aeaf-2deafc7a5ab1",
   "metadata": {},
   "source": [
    "#### 3. GELU Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab63d281-c0b2-497e-acd2-5a6dc2c9cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(\n",
    "            torch.sqrt(torch.tensor(2.0 / torch.pi)) * \n",
    "            (x + 0.044715 * torch.pow(x, 3))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cba4beb-f5b3-460a-9976-48ecb463af68",
   "metadata": {},
   "source": [
    "#### 4. Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "520196df-42b2-4f3f-a56f-629ca8fc86f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]), ## Expansion\n",
    "            GELU(), ## Activation\n",
    "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]), ## Contraction\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76cf25a-e617-43a8-9fd6-900410467918",
   "metadata": {},
   "source": [
    "Let us code a transformer block as follows:\n",
    "\n",
    "<b>Step 1</b>: Shortcut connection for attention block\n",
    "\n",
    "<b>Step 2</b>: Shortcut connection for feed forward block\n",
    "\n",
    "<b>Step 3</b>: Add the original input back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fabd729b-4015-469c-be22-28563b52ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.att = MultiHeadAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            d_out=cfg[\"emb_dim\"],\n",
    "            context_length=cfg[\"context_length\"],\n",
    "            num_heads=cfg[\"n_heads\"], \n",
    "            dropout=cfg[\"drop_rate\"],\n",
    "            qkv_bias=cfg[\"qkv_bias\"])\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.drop_shortcut = nn.Dropout(cfg[\"drop_rate\"])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shortcut connection for attention block\n",
    "        shortcut = x\n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x)  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # Shortcut connection for feed forward block\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        # 2*4*768\n",
    "        x = self.drop_shortcut(x)\n",
    "        x = x + shortcut  # Add the original input back\n",
    "\n",
    "        # 2*4*768\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a412264e-6e21-4883-bf79-ff44f3df7166",
   "metadata": {},
   "source": [
    "The given code defines a TransformerBlock class in PyTorch that includes a multi-head attention mechanism (MultiHeadAttention) and a feed forward network (FeedForward), both configured based on a provided configuration dictionary (cfg), such as GPT_CONFIG_124M.\n",
    "\n",
    "Layer normalization (LayerNorm) is applied before each of these two components, and dropout is applied after them to regularize the model and prevent overfitting. This is also known as Pre-LayerNorm. Older architectures, such as the original transformer model, applied layer normalization after the self-attention and feed-forward networks instead, known as Post-LayerNorm, which often leads to worse training dynamics.\n",
    "\n",
    "The class also implements the forward pass, where each component is followed by a shortcut connection that adds the input of the block to its output. This critical feature helps gradients flow through the network during training and improves the learning of deep models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f74ff-0a07-4f92-a0bb-9c69bb3cbc0a",
   "metadata": {},
   "source": [
    "Using the GPT_CONFIG_124M dictionary we defined earlier, let's instantiate a transformer block and feed it some sample data.\n",
    "\n",
    "Create sample input of shape [batch_size, num_tokens, emb_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a033bb7-4bff-4c7e-83e1-cefe949244f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 4, 768])\n",
      "Output shape: torch.Size([2, 4, 768])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "x = torch.rand(2, 4, 768) #A\n",
    "\n",
    "block = TransformerBlock(GPT_CONFIG_124M)\n",
    "output = block(x)\n",
    "print(\"Input shape:\", x.shape)\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47e566-00a4-4948-8faa-ac59b5c9c34f",
   "metadata": {},
   "source": [
    "As we can see from the code output, the transformer block maintains the input dimensions in its output, indicating that the transformer architecture processes sequences of data without altering their shape throughout the network.\n",
    "\n",
    "The preservation of shape throughout the transformer block architecture is not incidental but a crucial aspect of its design. This design enables its effective application across a wide range of sequence-to-sequence tasks, where each output vector directly corresponds to an input vector, maintaining a one-to-one relationship.\n",
    "\n",
    "However, the output is a context vector that encapsulates information from the entire input sequence. This means that while the physical dimensions of the sequence (length and feature size) remain unchanged as it passes through the transformer block, the content of each output vector is re-encoded to integrate contextual information from across the entire input sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158933a4-44dc-452f-aa31-b011bf76351f",
   "metadata": {},
   "source": [
    "## 6. Implementing GPT-2 Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "697dc3fb-99cc-4a55-89e7-0f4cea583404",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,    # Vocabulary size\n",
    "    \"context_length\": 1024, # Context length\n",
    "    \"emb_dim\": 768,         # Embedding dimension\n",
    "    \"n_heads\": 12,          # Number of attention heads\n",
    "    \"n_layers\": 12,         # Number of layers\n",
    "    \"drop_rate\": 0.1,       # Dropout rate\n",
    "    \"qkv_bias\": False       # Query-Key-Value bias\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cd680f3b-187c-470d-af84-aa8b3f298dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPTModel(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
    "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
    "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
    "        \n",
    "        self.trf_blocks = nn.Sequential(\n",
    "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
    "        \n",
    "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
    "        self.out_head = nn.Linear(\n",
    "            cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False\n",
    "        )\n",
    "\n",
    "    def forward(self, in_idx):\n",
    "        batch_size, seq_len = in_idx.shape\n",
    "        tok_embeds = self.tok_emb(in_idx)\n",
    "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
    "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
    "        x = self.drop_emb(x)\n",
    "        x = self.trf_blocks(x)\n",
    "        x = self.final_norm(x)\n",
    "        logits = self.out_head(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b78a3-bd39-415a-97b7-6c57a73476a0",
   "metadata": {},
   "source": [
    "The init constructor of this GPTModel class initializes the token and positional embedding layers using the configurations passed in via a Python dictionary, cfg. These embedding layers are responsible for converting input token indices into dense vectors and adding positional information.\n",
    "\n",
    "Next, the init method creates a sequential stack of TransformerBlock modules equal to the number of layers specified in cfg. Following the transformer blocks, a LayerNorm layer is applied, standardizing the outputs from the transformer blocks to stabilize the learning process.Finally, a linear output head without bias is defined, which projects the transformer's output into the vocabulary space of the tokenizer to generate logits for each token in the vocabulary.\n",
    "\n",
    "The forward method takes a batch of input token indices, computes their embeddings, applies the positional embeddings, passes the sequence through the transformer blocks, normalizes the final output, and then computes the logits, representing the next token's unnormalized probabilities. We will convert these logits into tokens and text outputs in the next section.\n",
    "\n",
    "Let's now initialize the 124 million parameter GPT model using the GPT_CONFIG_124M dictionary we pass into the cfg parameter and feed it with the batch text input we created at the beginning of this chapter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "55d6d6e0-a5c7-4e2a-9249-4978789b01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch:\n",
      " tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "\n",
      "Output shape: torch.Size([2, 4, 50257])\n",
      "tensor([[[ 0.3613,  0.4222, -0.0711,  ...,  0.3483,  0.4661, -0.2838],\n",
      "         [-0.1792, -0.5660, -0.9485,  ...,  0.0477,  0.5181, -0.3168],\n",
      "         [ 0.7120,  0.0332,  0.1085,  ...,  0.1018, -0.4327, -0.2553],\n",
      "         [-1.0076,  0.3418, -0.1190,  ...,  0.7195,  0.4023,  0.0532]],\n",
      "\n",
      "        [[-0.2564,  0.0900,  0.0335,  ...,  0.2659,  0.4454, -0.6806],\n",
      "         [ 0.1230,  0.3653, -0.2074,  ...,  0.7705,  0.2710,  0.2246],\n",
      "         [ 1.0558,  1.0318, -0.2800,  ...,  0.6936,  0.3205, -0.3178],\n",
      "         [-0.1565,  0.3926,  0.3288,  ...,  1.2630, -0.1858,  0.0388]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "out = model(batch)\n",
    "print(\"Input batch:\\n\", batch)\n",
    "print(\"\\nOutput shape:\", out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d34b0b-5509-4cdf-9f3a-0649b49fb489",
   "metadata": {},
   "source": [
    "As we can see, the output tensor has the shape [2, 4, 50257], since we passed in 2 input texts with 4 tokens each. The last dimension, 50,257, corresponds to the vocabulary size of the tokenizer. In the next section, we will see how to convert each of these 50,257- dimensional output vectors back into tokens.\n",
    "\n",
    "Using the numel() method, short for \"number of elements,\" we can collect the total number of parameters in the model's parameter tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e973adf-f751-4616-94fb-81d8b7af4029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 163,009,536\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total number of parameters: {total_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f71b5-3e89-4e78-806e-3d10eb1929b1",
   "metadata": {},
   "source": [
    "<b><u>NOTE</u></b>: Earlier, we spoke of initializing a 124 million parameter GPT model, so why is the actual number of parameters 163 million, as shown in the preceding code output?\n",
    "\n",
    "The reason is a concept called weight tying that is used in the original GPT-2 architecture, which means that the original GPT-2 architecture is reusing the weights from the token embedding layer in its output layer.\n",
    "\n",
    "To understand what this means, let's take a look at the shapes of the token embedding layer and linear output layer that we initialized on the model via the GPTModel earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0fb2dc8c-d6e1-4f83-9080-34b8223cdbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedding layer shape: torch.Size([50257, 768])\n",
      "Output layer shape: torch.Size([50257, 768])\n"
     ]
    }
   ],
   "source": [
    "print(\"Token embedding layer shape:\", model.tok_emb.weight.shape)\n",
    "print(\"Output layer shape:\", model.out_head.weight.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b002f5-0838-4200-9a66-6962d16fdee8",
   "metadata": {},
   "source": [
    "As we can see based on the print outputs, the weight tensors for both these layers have the same shape. The token embedding and output layers are very large due to the number of rows for the 50,257 in the tokenizer's vocabulary. Let's remove the output layer parameter count from the total GPT-2 model count according to the weight tying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a981bc8e-4058-45f8-b554-86ecb83f8046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters considering weight tying: 124,412,160\n"
     ]
    }
   ],
   "source": [
    "total_params_gpt2 = total_params - sum(p.numel() for p in model.out_head.parameters())\n",
    "print(f\"Number of trainable parameters considering weight tying: {total_params_gpt2:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a4aaa-d68e-4ecd-b6eb-96777548f9b7",
   "metadata": {},
   "source": [
    "As we can see, the model is now only 124 million parameters large, matching the original size of the GPT-2 model. Weight tying reduces the overall memory footprint and computational complexity of the model. However, in my experience, using separate token embedding and output layers results in better training and model performance; hence, we are using separate layers in our GPTModel implementation. The same is true for modern LLMs. Lastly, let us compute the memory requirements of the 163 million parameters in our GPTModel object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9d9bc47d-cb3c-40ad-85f1-2582dc9a6c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size of the model: 621.83 MB\n"
     ]
    }
   ],
   "source": [
    "total_size_bytes = total_params * 4 #A\n",
    "total_size_mb = total_size_bytes / (1024 * 1024) #B\n",
    "print(f\"Total size of the model: {total_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746237f1-8aa5-49ae-a256-6d2eefd5be38",
   "metadata": {},
   "source": [
    "In conclusion, by calculating the memory requirements for the 163 million parameters in our GPTModel object and assuming each parameter is a 32-bit float taking up 4 bytes, we find that the total size of the model amounts to 621.83 MB, illustrating the relatively large storage capacity required to accommodate even relatively small LLMs.\n",
    "\n",
    "In conclusion, by calculating the memory requirements for the 163 million parameters in our GPTModel object and assuming each parameter is a 32-bit float taking up 4 bytes, we find that the total size of the model amounts to 621.83 MB, illustrating the relatively large storage capacity required to accommodate even relatively small LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04eee1-4a32-4528-a343-c1d1e32821d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
